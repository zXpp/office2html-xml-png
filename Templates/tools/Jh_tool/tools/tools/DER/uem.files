I'm not sure what uem stands for but it usually just contains one line with the file name and a start and end time for the scoring.

So for example below, for the file TBL0101-MIXA1 on channel one, the scoring only considers audio between the times 37.13 s and 2370.51 s. This is because there is unscripted chat before 37.13 s which is not in the transcript/reference so we want to ignore that time.

#filename        channel     starttime (second)     endtime (second)
TBL0101-MIXA1       1           37.13                 2370.51




################################

Along with all audio files an index file will be distributed indicating the segments within the audio files
that are part of the evaluation. The format of these files will be NIST Unpartitioned Evaluation Map
(UEM) files. These ASCII text files consist of 4 fields, the semantics are in Table 7. Each line in
the UEM indicates a segment in an audio file that must be processed by the speech recognition system.
Several segments within the same audio file can be referenced, as well as one or two channels for CTS
data.

          Table 7  Fields in the UEM format
--------------------------------------------------------------
Field  |    Meaning                           |  example  
--------------------------------------------------------------
1      |  source ID (filename)                |   cn01345
2      |  channel (1â€“2)                       |    1
3      |  evaluation segment start time (sec) |    5.456
4      |  evaluation segment end time (sec)   |    342.211
--------------------------------------------------------------


Reference: 
Nijmegen, PDF hosted at the Radboud Repository of the Radboud University 
