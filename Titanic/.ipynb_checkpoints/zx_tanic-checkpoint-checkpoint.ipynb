{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tanic=pd.read_csv(\"titanic_train.csv\")\n",
    "tanic.head()#默认显示前5行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000         NaN    0.000000   \n",
      "50%     446.000000    0.000000    3.000000         NaN    0.000000   \n",
      "75%     668.500000    1.000000    3.000000         NaN    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzpp220/anaconda2/lib/python2.7/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "数据预处理：包括数据清洗，丢掉脏数据，填充缺失值，数值转换（映射）等。\n",
    "\"\"\"\n",
    "#第一步：检查各列特征下是否有缺失值\n",
    "print tanic.describe()#按列进行统计，由age看到，714<891，数据缺失了，而其他各列的count值都是891，即没有缺失。因此要对数据进行预处理，缺失值填充-选择均值-mean填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.560236    0.523008   \n",
      "std     257.353842    0.486592    0.836071   13.005010    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   29.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   35.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "tanic[\"Age\"]=tanic[\"Age\"].fillna(int(tanic[\"Age\"].mean()))#这里age是int类型，可以选用中位数median，也可以选平均数近似为29\n",
    "##！注意，fillna 并不是原地修改，而是返回一个新的值，因此要将新的赋值给原来旧的\n",
    "print tanic.describe() #只会显示该列的取值为数值型的统计数据，字符型等其他非数值性的则不会显示\n",
    "#由describe可知各列无缺失值，都是891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 29.0\n"
     ]
    }
   ],
   "source": [
    "print int(tanic[\"Age\"].mean()),tanic[\"Age\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method mean in module pandas.core.generic:\n",
      "\n",
      "mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs) method of pandas.core.series.Series instance\n",
      "    Return the mean of the values for the requested axis\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    axis : {index (0)}\n",
      "    skipna : boolean, default True\n",
      "        Exclude NA/null values. If an entire row/column is NA, the result\n",
      "        will be NA\n",
      "    level : int or level name, default None\n",
      "        If the axis is a MultiIndex (hierarchical), count along a\n",
      "        particular level, collapsing into a scalar\n",
      "    numeric_only : boolean, default None\n",
      "        Include only float, int, boolean data. If None, will attempt to use\n",
      "        everything, then use only numeric data\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    mean : scalar or Series (if level specified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tanic[\"Age\"].mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method median in module pandas.core.generic:\n",
      "\n",
      "median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs) method of pandas.core.series.Series instance\n",
      "    Return the median of the values for the requested axis\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    axis : {index (0)}\n",
      "    skipna : boolean, default True\n",
      "        Exclude NA/null values. If an entire row/column is NA, the result\n",
      "        will be NA\n",
      "    level : int or level name, default None\n",
      "        If the axis is a MultiIndex (hierarchical), count along a\n",
      "        particular level, collapsing into a scalar\n",
      "    numeric_only : boolean, default None\n",
      "        Include only float, int, boolean data. If None, will attempt to use\n",
      "        everything, then use only numeric data\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    median : scalar or Series (if level specified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tanic[\"Age\"].median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\xe6\\x8e\\xa5\\xe4\\xb8\\x8b\\xe6\\x9d\\xa5\\xe8\\xa6\\x81\\xe7\\xa0\\x94\\xe7\\xa9\\xb6\\xe5\\x93\\xaa\\xe4\\xba\\x9b\\xe7\\x89\\xb9\\xe5\\xbe\\x81\\xe5\\xbd\\xb1\\xe5\\x93\\x8d\\xe8\\xaf\\xa5\\xe6\\xa0\\xb7\\xe6\\x9c\\xac\\xe8\\x83\\xbd\\xe5\\x90\\xa6\\xe8\\x8e\\xb7\\xe6\\x95\\x91\\xef\\xbc\\x8c\\xe8\\xbf\\x99\\xe4\\xba\\x9b\\xe7\\x89\\xb9\\xe5\\xbe\\x81\\xe7\\x9a\\x84\\xe5\\xbd\\xb1\\xe5\\x93\\x8d\\xe7\\xa8\\x8b\\xe5\\xba\\xa6\\xe6\\x98\\xaf\\xe6\\x80\\x8e\\xe6\\xa0\\xb7\\xe7\\x9a\\x84\\xef\\xbc\\x8c\\xe9\\x82\\xa3\\xe4\\xb8\\xaa\\xe6\\x9c\\x80\\xe5\\xa4\\xa7\\xef\\xbc\\x9f\\n\\xe6\\x98\\xbe\\xe7\\x84\\xb6\\xef\\xbc\\x8c\\xe8\\xbf\\x99\\xe6\\x98\\xaf\\xe4\\xb8\\x80\\xe4\\xb8\\xaa\\xe5\\x88\\x86\\xe7\\xb1\\xbb\\xe9\\x97\\xae\\xe9\\xa2\\x98\\xef\\xbc\\x8c\\xe4\\xba\\x8c\\xe5\\x88\\x86\\xe7\\xb1\\xbb\\xe3\\x80\\x82\\n\\xe7\\xac\\xac\\xe4\\xba\\x8c\\xe6\\xad\\xa5\\xef\\xbc\\x9a\\xe5\\xb0\\x86\\xe6\\xa1\\x88\\xe4\\xbe\\x8b\\xe4\\xb8\\xad\\xe7\\x9a\\x84\\xe5\\x90\\x84\\xe7\\x89\\xb9\\xe5\\xbe\\x81\\xe7\\x9a\\x84\\xe6\\xa0\\xb7\\xe6\\x9c\\xac\\xe5\\x80\\xbc\\xe8\\xbd\\xac\\xe5\\x8c\\x96\\xe4\\xb8\\xba\\xe5\\x8f\\xaf\\xe4\\xbb\\xa5\\xe7\\x94\\xa8\\xe8\\xae\\xa1\\xe7\\xae\\x97\\xe6\\x9c\\xba\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe3\\x80\\x81\\xe6\\xa8\\xa1\\xe5\\x9e\\x8b\\xe5\\xa4\\x84\\xe7\\x90\\x86\\xe7\\x9a\\x84\\xe5\\x80\\xbc\\xe7\\x9a\\x84\\xe5\\xbd\\xa2\\xe5\\xbc\\x8f\\xef\\xbc\\x8c\\xe4\\xbe\\x8b\\xe5\\xa6\\x82\\xe5\\xb0\\x86str\\xe7\\xb1\\xbb\\xe5\\x9e\\x8b\\xe8\\xbd\\xac\\xe6\\x8d\\xa2\\xe4\\xb8\\xbaint\\xe5\\x9e\\x8b\\xef\\xbc\\x8c\\xe5\\x8d\\xb3\\xe6\\x95\\xb0\\xe5\\x80\\xbc\\xe8\\xbd\\xac\\xe6\\x8d\\xa2\\xe3\\x80\\x82\\n\\xe5\\x85\\x88\\xe6\\x89\\xab\\xe6\\x8f\\x8f\\xe4\\xb8\\x80\\xe9\\x81\\x8d\\xe9\\x82\\xa3\\xe4\\xba\\x9b\\xe7\\x89\\xb9\\xe5\\xbe\\x81\\xe7\\x9a\\x84\\xe5\\x8f\\x96\\xe5\\x80\\xbc\\xe6\\x98\\xaf\\xe9\\x9d\\x9e\\xe6\\x95\\xb0\\xe5\\x80\\xbc\\xef\\xbc\\x8c\\xe7\\x89\\xb9\\xe5\\xbe\\x81\\xe5\\x8f\\x96\\xe5\\x80\\xbc\\xe4\\xb8\\x80\\xe5\\x85\\xb1\\xe5\\x93\\x9f\\xe5\\x93\\xaa\\xe5\\x87\\xa0\\xe7\\xa7\\x8d\\xef\\xbc\\x8c\\xe4\\xb8\\xba\\xe8\\xbf\\x99\\xe4\\xba\\x9b\\xe5\\x8f\\x96\\xe5\\x80\\xbc\\xe5\\x88\\x86\\xe5\\x88\\xab\\xe5\\x81\\x9a\\xe4\\xb8\\x80\\xe4\\xb8\\xaa\\xe9\\x9d\\x9e\\xe6\\x95\\xb0\\xe5\\x80\\xbc\\xe6\\x80\\xa7\\xe5\\x88\\xb0\\xe6\\x95\\xb0\\xe5\\x80\\xbc\\xe5\\x9e\\x8b\\xe7\\x9a\\x84\\xe6\\x98\\xa0\\xe5\\xb0\\x84\\xe3\\x80\\x82\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "接下来要研究哪些特征影响该样本能否获救，这些特征的影响程度是怎样的，那个最大？\n",
    "显然，这是一个分类问题，二分类。\n",
    "第二步：将案例中的各特征的样本值转化为可以用计算机语言、模型处理的值的形式，例如将str类型转换为int型，即数值转换。\n",
    "先扫描一遍那些特征的取值是非数值，特征取值一共哟哪几种，为这些取值分别做一个非数值性到数值型的映射。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sex     Sex   \n",
       "female  female    314\n",
       "male    male      577\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#首先看性别,取值只有两种，且为str类型\n",
    "print tanic[\"Sex\"].unique()\n",
    "#性别各取值的人数分布。男的比女的多\n",
    "tanic[\"Sex\"].groupby(tanic[\"Sex\"]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on _LocIndexer in module pandas.core.indexing object:\n",
      "\n",
      "class _LocIndexer(_LocationIndexer)\n",
      " |  Purely label-location based indexer for selection by label.\n",
      " |  \n",
      " |  ``.loc[]`` is primarily label based, but may also be used with a\n",
      " |  boolean array.\n",
      " |  \n",
      " |  Allowed inputs are:\n",
      " |  \n",
      " |  - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      " |    interpreted as a *label* of the index, and **never** as an\n",
      " |    integer position along the index).\n",
      " |  - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      " |  - A slice object with labels, e.g. ``'a':'f'`` (note that contrary\n",
      " |    to usual python slices, **both** the start and the stop are included!).\n",
      " |  - A boolean array.\n",
      " |  - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      " |    or Panel) and that returns valid output for indexing (one of the above)\n",
      " |  \n",
      " |  ``.loc`` will raise a ``KeyError`` when the items are not found.\n",
      " |  \n",
      " |  See more at :ref:`Selection by Label <indexing.label>`\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      _LocIndexer\n",
      " |      _LocationIndexer\n",
      " |      _NDFrameIndexer\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods inherited from _LocationIndexer:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _NDFrameIndexer:\n",
      " |  \n",
      " |  __call__(self, axis=None)\n",
      " |  \n",
      " |  __init__(self, obj, name)\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _NDFrameIndexer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from _NDFrameIndexer:\n",
      " |  \n",
      " |  axis = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#数值转化 \n",
    "help(tanic.loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#定位SEX属性的行，并且做数值映射 ，替换原来的值.loc[row_indexer,col_indexer] = value instead\n",
    "\n",
    "tanic.loc[tanic[\"Sex\"]==\"male\",\"Sex\"]=0\n",
    "tanic.loc[tanic[\"Sex\"]==\"female\",\"Sex\"]=1\n",
    "tanic[\"Sex\"].unique()\n",
    "#看如下结果，修改完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#还有Embarked 列。代表登船地点，同样的方法处理\n",
    "tanic[\"Embarked\"].unique()#array(['S', 'C', 'Q', nan], dtype=object)\n",
    "#发现有缺失值，首先进行填充，--看各其他取非nan值的分布--groupby\n",
    "tanic[\"Embarked\"].value_counts(dropna=False)#不要扔掉nan\n",
    "\"\"\"\n",
    "S      644\n",
    "C      168\n",
    "Q       77\n",
    "NaN      2\n",
    "Name: Embarked, dtype: int64\n",
    "\n",
    "将nan的样本用最多的取值“S”进行填充\n",
    "\"\"\"\n",
    "tanic[\"Embarked\"]=tanic[\"Embarked\"].fillna(\"S\")#将填充后的列替换填充前的列\n",
    "#填充完缺失值再进行数值映射，替换原来的值\n",
    "tanic.loc[tanic[\"Embarked\"]==\"S\",\"Embarked\"]=0\n",
    "tanic.loc[tanic[\"Embarked\"]==\"C\",\"Embarked\"]=1\n",
    "tanic.loc[tanic[\"Embarked\"]==\"Q\",\"Embarked\"]=2\n",
    "tanic[\"Embarked\"].unique()\n",
    "#替换完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 7)\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzpp220/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "接下来，选取用来进行分类的样本特征以及分类器建立模型\n",
    "\"\"\"\n",
    "#首先选择表中最直接观测可以作为特征的属性，浅层的，不涉及特征的组合和特征选择\n",
    "features=[\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Embarked\"]\n",
    "from sklearn.linear_model import LinearRegression#引入线性回归模型\n",
    "from sklearn.cross_validation import KFold #引入K折交叉验证\n",
    "\n",
    "line_model=LinearRegression()#初始化线性回归模型对象\n",
    "#sklearn.cross_validation.KFold(n=4, n_folds=2, shuffle=False,random_state=None)\n",
    "\n",
    "print tanic[features].shape #返回（行数，列数）\n",
    "\n",
    "kf=KFold(tanic[features].shape[0],n_folds=5,random_state=1)#输入样本数、要将训练集分为几分\n",
    "#每一次都会训练模型，一共5次，最后的结果是5次结果的平均。\n",
    "print len(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on _iLocIndexer in module pandas.core.indexing object:\n",
      "\n",
      "class _iLocIndexer(_LocationIndexer)\n",
      " |  Purely integer-location based indexing for selection by position.\n",
      " |  \n",
      " |  ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      " |  ``length-1`` of the axis), but may also be used with a boolean\n",
      " |  array.\n",
      " |  \n",
      " |  Allowed inputs are:\n",
      " |  \n",
      " |  - An integer, e.g. ``5``.\n",
      " |  - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      " |  - A slice object with ints, e.g. ``1:7``.\n",
      " |  - A boolean array.\n",
      " |  - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      " |    or Panel) and that returns valid output for indexing (one of the above)\n",
      " |  \n",
      " |  ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      " |  out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      " |  indexing (this conforms with python/numpy *slice* semantics).\n",
      " |  \n",
      " |  See more at :ref:`Selection by Position <indexing.integer>`\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      _iLocIndexer\n",
      " |      _LocationIndexer\n",
      " |      _NDFrameIndexer\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods inherited from _LocationIndexer:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _NDFrameIndexer:\n",
      " |  \n",
      " |  __call__(self, axis=None)\n",
      " |  \n",
      " |  __init__(self, obj, name)\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _NDFrameIndexer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from _NDFrameIndexer:\n",
      " |  \n",
      " |  axis = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tanic.iloc)#按照下标进行定位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass Sex   Age  SibSp  Parch      Fare Embarked\n",
      "0         3   0  22.0      1      0    7.2500        0\n",
      "1         1   1  38.0      1      0   71.2833        1\n",
      "2         3   1  26.0      0      0    7.9250        0\n",
      "3         1   1  35.0      1      0   53.1000        0\n",
      "4         3   0  35.0      0      0    8.0500        0\n",
      "5         3   0  29.0      0      0    8.4583        2\n",
      "6         1   0  54.0      0      0   51.8625        0\n",
      "7         3   0   2.0      3      1   21.0750        0\n",
      "8         3   1  27.0      0      2   11.1333        0\n",
      "9         2   1  14.0      1      0   30.0708        1\n",
      "10        3   1   4.0      1      1   16.7000        0\n",
      "11        1   1  58.0      0      0   26.5500        0\n",
      "12        3   0  20.0      0      0    8.0500        0\n",
      "13        3   0  39.0      1      5   31.2750        0\n",
      "14        3   1  14.0      0      0    7.8542        0\n",
      "15        2   1  55.0      0      0   16.0000        0\n",
      "16        3   0   2.0      4      1   29.1250        2\n",
      "17        2   0  29.0      0      0   13.0000        0\n",
      "18        3   1  31.0      1      0   18.0000        0\n",
      "19        3   1  29.0      0      0    7.2250        1\n",
      "20        2   0  35.0      0      0   26.0000        0\n",
      "21        2   0  34.0      0      0   13.0000        0\n",
      "22        3   1  15.0      0      0    8.0292        2\n",
      "23        1   0  28.0      0      0   35.5000        0\n",
      "24        3   1   8.0      3      1   21.0750        0\n",
      "25        3   1  38.0      1      5   31.3875        0\n",
      "26        3   0  29.0      0      0    7.2250        1\n",
      "27        1   0  19.0      3      2  263.0000        0\n",
      "28        3   1  29.0      0      0    7.8792        2\n",
      "29        3   0  29.0      0      0    7.8958        0\n",
      "..      ...  ..   ...    ...    ...       ...      ...\n",
      "861       2   0  21.0      1      0   11.5000        0\n",
      "862       1   1  48.0      0      0   25.9292        0\n",
      "863       3   1  29.0      8      2   69.5500        0\n",
      "864       2   0  24.0      0      0   13.0000        0\n",
      "865       2   1  42.0      0      0   13.0000        0\n",
      "866       2   1  27.0      1      0   13.8583        1\n",
      "867       1   0  31.0      0      0   50.4958        0\n",
      "868       3   0  29.0      0      0    9.5000        0\n",
      "869       3   0   4.0      1      1   11.1333        0\n",
      "870       3   0  26.0      0      0    7.8958        0\n",
      "871       1   1  47.0      1      1   52.5542        0\n",
      "872       1   0  33.0      0      0    5.0000        0\n",
      "873       3   0  47.0      0      0    9.0000        0\n",
      "874       2   1  28.0      1      0   24.0000        1\n",
      "875       3   1  15.0      0      0    7.2250        1\n",
      "876       3   0  20.0      0      0    9.8458        0\n",
      "877       3   0  19.0      0      0    7.8958        0\n",
      "878       3   0  29.0      0      0    7.8958        0\n",
      "879       1   1  56.0      0      1   83.1583        1\n",
      "880       2   1  25.0      0      1   26.0000        0\n",
      "881       3   0  33.0      0      0    7.8958        0\n",
      "882       3   1  22.0      0      0   10.5167        0\n",
      "883       2   0  28.0      0      0   10.5000        0\n",
      "884       3   0  25.0      0      0    7.0500        0\n",
      "885       3   1  39.0      0      5   29.1250        2\n",
      "886       2   0  27.0      0      0   13.0000        0\n",
      "887       1   1  19.0      0      0   30.0000        0\n",
      "888       3   1  29.0      1      2   23.4500        0\n",
      "889       1   0  26.0      0      0   30.0000        1\n",
      "890       3   0  32.0      0      0    7.7500        2\n",
      "\n",
      "[891 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print tanic[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_score=[]#存放每次交叉验证的结果,\n",
    "'''注意 这次并没哟真正意义上的测试数据，整个列表看做训练数据的话。交叉验证只是为了让模型的训练误差尽量小，\n",
    "。训练好的 的模型并没哟真正用到独立与整个训练集的测试集。\n",
    "'''\n",
    "for train ,test in kf:#每次都要训练模型\n",
    "    \n",
    "    train_features=tanic[features].iloc[train,:]#在所有样本上述特征中取出train的样本特征【row_index,col_indexer】\n",
    "    train_label=tanic[\"Survived\"].iloc[train] #取出上面训练样本特征对应的标签\n",
    "    line_model.fit(train_features,train_label)#训练模型\n",
    "    test_sysout=line_model.predict(tanic[features].iloc[test,:])#本次的测试集上应用模型，得到系统输出,是一个数组\n",
    "    pred_score.append(test_sysout)#将每一次的测试结果收集。\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(179,), (178,), (178,), (178,), (178,)]\n"
     ]
    }
   ],
   "source": [
    "print [i.shape for i in pred_score]#每一组都是平均178个样本的概率值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function concatenate in module numpy.core.multiarray:\n",
      "\n",
      "concatenate(...)\n",
      "    concatenate((a1, a2, ...), axis=0)\n",
      "    \n",
      "    Join a sequence of arrays along an existing axis.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a1, a2, ... : sequence of array_like\n",
      "        The arrays must have the same shape, except in the dimension\n",
      "        corresponding to `axis` (the first, by default).\n",
      "    axis : int, optional\n",
      "        The axis along which the arrays will be joined.  Default is 0.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    res : ndarray\n",
      "        The concatenated array.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    ma.concatenate : Concatenate function that preserves input masks.\n",
      "    array_split : Split an array into multiple sub-arrays of equal or\n",
      "                  near-equal size.\n",
      "    split : Split array into a list of multiple sub-arrays of equal size.\n",
      "    hsplit : Split array into multiple sub-arrays horizontally (column wise)\n",
      "    vsplit : Split array into multiple sub-arrays vertically (row wise)\n",
      "    dsplit : Split array into multiple sub-arrays along the 3rd axis (depth).\n",
      "    stack : Stack a sequence of arrays along a new axis.\n",
      "    hstack : Stack arrays in sequence horizontally (column wise)\n",
      "    vstack : Stack arrays in sequence vertically (row wise)\n",
      "    dstack : Stack arrays in sequence depth wise (along third dimension)\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    When one or more of the arrays to be concatenated is a MaskedArray,\n",
      "    this function will return a MaskedArray object instead of an ndarray,\n",
      "    but the input masks are *not* preserved. In cases where a MaskedArray\n",
      "    is expected as input, use the ma.concatenate function from the masked\n",
      "    array module instead.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1, 2], [3, 4]])\n",
      "    >>> b = np.array([[5, 6]])\n",
      "    >>> np.concatenate((a, b), axis=0)\n",
      "    array([[1, 2],\n",
      "           [3, 4],\n",
      "           [5, 6]])\n",
      "    >>> np.concatenate((a, b.T), axis=1)\n",
      "    array([[1, 2, 5],\n",
      "           [3, 4, 6]])\n",
      "    \n",
      "    This function will not preserve masking of MaskedArray inputs.\n",
      "    \n",
      "    >>> a = np.ma.arange(3)\n",
      "    >>> a[1] = np.ma.masked\n",
      "    >>> b = np.arange(2, 5)\n",
      "    >>> a\n",
      "    masked_array(data = [0 -- 2],\n",
      "                 mask = [False  True False],\n",
      "           fill_value = 999999)\n",
      "    >>> b\n",
      "    array([2, 3, 4])\n",
      "    >>> np.concatenate([a, b])\n",
      "    masked_array(data = [0 1 2 2 3 4],\n",
      "                 mask = False,\n",
      "           fill_value = 999999)\n",
      "    >>> np.ma.concatenate([a, b])\n",
      "    masked_array(data = [0 -- 2 2 3 4],\n",
      "                 mask = [False  True False False False False],\n",
      "           fill_value = 999999)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "help(np.concatenate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.02592107e-01,   9.44255295e-01,   5.91815855e-01,\n",
       "         9.15870978e-01,   5.52881039e-02,   1.69428484e-01,\n",
       "         3.49092646e-01,   1.41787102e-01,   5.35692777e-01,\n",
       "         8.76262616e-01,   6.70944170e-01,   7.98001884e-01,\n",
       "         1.44847994e-01,  -1.17936142e-01,   6.63435658e-01,\n",
       "         6.16798986e-01,   1.93140481e-01,   2.88003623e-01,\n",
       "         5.35965583e-01,   6.12703123e-01,   2.57340928e-01,\n",
       "         2.58150327e-01,   7.35688798e-01,   4.97833548e-01,\n",
       "         5.88804591e-01,   3.70920627e-01,   1.29861679e-01,\n",
       "         5.00474505e-01,   6.52040014e-01,   9.10508394e-02,\n",
       "         4.62174298e-01,   1.02786202e+00,   6.51988719e-01,\n",
       "         6.60966784e-02,   5.25442999e-01,   3.90798196e-01,\n",
       "         1.29863346e-01,   1.38877334e-01,   5.83587202e-01,\n",
       "         6.73860772e-01,   4.78845054e-01,   7.55965595e-01,\n",
       "         1.30128000e-01,   8.95082755e-01,   7.11746607e-01,\n",
       "         9.11120598e-02,   1.42227227e-01,   6.51988719e-01,\n",
       "         7.56063813e-02,   6.13504751e-01,   8.93263885e-02,\n",
       "         1.38778079e-01,   8.80740174e-01,   7.46009377e-01,\n",
       "         3.00795997e-01,   4.91862889e-01,   8.17617793e-01,\n",
       "         1.32848676e-01,   8.38573807e-01,   1.25972167e-02,\n",
       "         1.71657961e-01,   9.38635791e-01,   3.85382424e-01,\n",
       "         1.06842355e-01,   5.27851551e-01,   7.73360553e-02,\n",
       "         7.69852518e-01,   1.50861650e-01,   4.74137802e-01,\n",
       "         4.92733083e-02,   2.69099095e-01,   4.65585365e-01,\n",
       "         3.59788610e-01,   1.20646842e-01,   9.24340352e-02,\n",
       "         1.14835889e-01,   9.10508394e-02,   9.11120598e-02,\n",
       "         4.11123238e-01,   5.69739659e-01,   1.33283844e-01,\n",
       "         9.16877389e-02,   6.52003607e-01,   5.02438980e-01,\n",
       "         8.41500430e-01,   4.63176767e-01,   7.20459632e-02,\n",
       "         9.11120598e-02,   9.59433313e-01,   1.20965356e-01,\n",
       "         9.11120598e-02,   1.44770257e-01,   3.70558218e-01,\n",
       "         3.25735829e-02,  -8.83253359e-02,   9.11120598e-02,\n",
       "         2.79836558e-01,   5.52111219e-01,   7.19248883e-01,\n",
       "         2.33314635e-01,   5.79862944e-01,   9.10508394e-02,\n",
       "         5.30505549e-01,   6.74693021e-02,  -1.66967465e-02,\n",
       "         9.70214987e-02,   6.21559971e-01,   9.10028793e-02,\n",
       "         3.73149055e-02,   6.28502896e-01,   3.90941852e-01,\n",
       "         6.72150869e-01,   1.32906675e-01,   5.98397197e-01,\n",
       "         6.87222800e-01,   1.38827707e-01,  -7.86350876e-02,\n",
       "         2.61182832e-01,   6.19256762e-01,   5.72968110e-01,\n",
       "         2.99794706e-01,   9.11120598e-02,   2.82963974e-01,\n",
       "         7.49947761e-01,   3.33473791e-01,   2.02960645e-01,\n",
       "         1.69147274e-01,   1.20604743e-01,   5.63001305e-01,\n",
       "        -4.84528585e-03,   1.06245362e-01,   1.44450974e-01,\n",
       "         4.39045464e-01,   7.46009377e-01,   3.11886261e-01,\n",
       "         3.63716963e-01,   9.79325534e-01,   4.21088215e-01,\n",
       "         1.69193834e-01,   5.78143121e-01,   5.64461363e-01,\n",
       "         6.15629014e-01,   5.76906606e-01,   2.28456847e-01,\n",
       "         3.53085346e-01,   3.01429401e-01,   1.02952456e-01,\n",
       "         5.92398161e-01,   1.96958760e-01,   2.10385052e-01,\n",
       "         1.56460534e-01,   9.98849320e-01,  -6.71104122e-02,\n",
       "        -2.64159219e-02,   9.08192576e-02,   3.84147015e-01,\n",
       "         7.29600660e-01,   8.51414005e-02,   9.13552346e-02,\n",
       "        -1.75873004e-01,  -2.09649081e-02,   7.06259621e-01,\n",
       "         1.08914857e-01,   1.63003146e-01,   1.25150344e-01,\n",
       "         1.64051892e-01,   9.56733135e-01,   3.53454494e-01,\n",
       "         4.88061422e-01,   1.16316673e-01,   3.00007750e-01,\n",
       "         1.81199163e-01,   6.86646056e-01,   1.38827707e-01,\n",
       "         3.67824884e-01,   1.01001534e-01,  -1.76771070e-02,\n",
       "         8.85702875e-01,   2.82032964e-01,   4.48313063e-02,\n",
       "         1.44419756e-01,   3.14129689e-01,  -3.59057354e-02,\n",
       "         3.28010323e-01,   7.13002619e-01,   4.80987622e-01,\n",
       "         6.07805185e-01,   3.79881886e-01,   2.29026880e-02,\n",
       "         4.71584434e-02,   7.66842635e-01,   3.38849127e-01,\n",
       "         5.97327570e-01,   3.66830955e-01,   9.24188270e-01,\n",
       "         8.76782306e-01,   1.55421069e-01,  -3.63212383e-03,\n",
       "         6.59947441e-01,   8.13939782e-01,   9.47283977e-02,\n",
       "        -3.60106615e-01,   5.85201067e-02,   2.45806730e-02,\n",
       "         1.53172471e-01,   7.36986627e-01,   1.86249449e-02,\n",
       "         1.42787796e-01,   7.36480304e-01,   4.44176953e-01,\n",
       "         1.17554880e-01,   7.51539053e-01,   1.29388113e-01,\n",
       "         2.74090551e-01,   1.00994648e-01,   9.71510187e-01,\n",
       "         6.04677711e-01,   1.53144643e-01,   1.00914934e+00,\n",
       "         2.73353723e-01,   1.64946758e-01,   2.91751981e-01,\n",
       "        -4.11032594e-02,   8.83684468e-02,   3.85366151e-01,\n",
       "         1.30007048e-01,   3.38112300e-01,   1.38218828e-01,\n",
       "         3.44736271e-01,   4.19176695e-01,   9.05630833e-01,\n",
       "         8.83328433e-02,   1.03510759e-01,   4.92169210e-01,\n",
       "         3.08676583e-01,   5.92792900e-01,   1.41075625e-01,\n",
       "         8.80804165e-01,   3.38112300e-01,   2.56215441e-01,\n",
       "         5.73949158e-01,   6.07805185e-01,   2.79240866e-01,\n",
       "         1.29351272e-01,   1.15831395e-01,   3.62712464e-01,\n",
       "         6.16407788e-01,   7.83146782e-01,   3.64599308e-01,\n",
       "         8.22041919e-02,   8.81781096e-02,   5.23607335e-01,\n",
       "         2.79800449e-01,   3.04729144e-02,   4.94644115e-01,\n",
       "         5.97373792e-01,   1.02766794e+00,   9.90384532e-01,\n",
       "         1.12000168e+00,   6.49088010e-01,   1.55421069e-01,\n",
       "        -5.82875297e-04,   2.84278130e-01,   4.01492495e-01,\n",
       "         6.59947441e-01,   2.38030863e-01,  -5.90519232e-02,\n",
       "         5.74549955e-02,   8.29662895e-01,   9.75429922e-01,\n",
       "         4.75387733e-01,   1.09589883e-01,   7.00156548e-01,\n",
       "         4.45837685e-01,   6.59947441e-01,   7.39164876e-01,\n",
       "         4.98657553e-01,   2.76146191e-01,   5.79148648e-02,\n",
       "         4.91169155e-01,  -5.65160915e-02,   9.42433294e-02,\n",
       "         1.65374118e-01,   1.47285328e-01,   4.73914078e-01,\n",
       "         9.85936407e-02,   8.29541110e-02,   1.29578450e-01,\n",
       "         2.03444830e-01,   7.01157444e-01,   1.01167841e+00,\n",
       "         1.03561412e+00,   2.72278646e-01,   6.22611768e-01,\n",
       "         1.17804164e-01,   5.07969048e-01,   1.54099065e-01,\n",
       "         1.08873528e+00,   4.75240368e-01,   9.38029736e-01,\n",
       "         6.59947441e-01,   5.11365573e-02,   1.44912743e-01,\n",
       "         8.51408084e-01,   8.84138944e-02,   5.90567023e-01,\n",
       "         1.03700599e+00,   1.05264075e+00,   2.56453967e-01,\n",
       "         1.01521690e+00,   1.05827029e+00,   1.00632593e+00,\n",
       "         7.35953029e-01,   9.42555902e-02,   1.31418903e-01,\n",
       "         6.10543988e-01,   7.63344864e-01,   1.33093841e-01,\n",
       "         9.76359388e-01,   9.09164014e-01,   1.29388113e-01,\n",
       "         1.00142734e-01,   8.45520941e-01,   7.60385795e-01,\n",
       "        -3.60106615e-01,   1.00309058e+00,  -1.00508893e-01,\n",
       "         7.43294062e-01,   5.14798779e-01,   1.08232882e+00,\n",
       "         5.55662929e-01,   3.77513040e-01,   4.42879390e-01,\n",
       "         5.90264890e-02,   9.55741821e-01,   8.83684468e-02,\n",
       "         4.31453736e-01,   9.73320841e-01,  -5.78039925e-03,\n",
       "         3.82519729e-01,   3.72718098e-01,   8.83213054e-01,\n",
       "         2.85864837e-01,   3.03526267e-01,   2.38767690e-01,\n",
       "         8.13939782e-01,   7.19745489e-01,   5.40886429e-01,\n",
       "         1.73749290e-01,   1.20615535e-02,   1.24083063e-01,\n",
       "         4.76566657e-01,   1.34095814e-01,   6.04096738e-02,\n",
       "         1.21718538e-01,   9.47283977e-02,   1.01258010e+00,\n",
       "         7.13838337e-01,   6.90298332e-01,   6.90298332e-01,\n",
       "        -8.65031059e-02,   2.72590314e-01,   5.31519673e-01,\n",
       "         6.29917880e-02,   1.47210886e-01,   9.37956324e-02,\n",
       "         7.76851745e-01,   6.47602172e-01,   6.90219914e-01,\n",
       "         1.03648592e+00,   4.74225179e-01,   1.24643877e-01,\n",
       "         1.61782593e-01,   5.83639069e-01,   6.23973519e-01,\n",
       "         9.71283559e-01,   6.48268592e-01,   5.54436375e-01,\n",
       "         1.95497170e-01,   1.61615681e-01,   1.02206424e+00,\n",
       "         7.80022836e-01,   8.19323442e-02,   8.73850715e-01,\n",
       "         1.00324093e-01,   3.67907778e-01,   3.95923865e-02,\n",
       "         7.26111318e-01,   1.84826255e-01,   8.84399330e-01,\n",
       "         3.59038233e-01,   1.49355324e-01,   2.18145467e-02,\n",
       "         1.02698129e+00,   5.97163552e-01,   1.43218833e-01,\n",
       "         5.93406896e-01,   1.67255767e-01,   2.98987282e-01,\n",
       "         7.74990811e-01,   3.89769089e-02,   1.18827158e-01,\n",
       "         6.13636107e-01,   6.89565300e-02,   6.61398895e-01,\n",
       "         1.95527010e-01,  -3.47671970e-02,   3.62108697e-01,\n",
       "         1.49342700e-01,   4.67090315e-01,   1.00324093e-01,\n",
       "         1.84297660e-01,   9.93791193e-01,   2.55795330e-01,\n",
       "         8.29445507e-03,   6.05798719e-01,   6.85604121e-01,\n",
       "         7.92000386e-01,   2.57549229e-01,   6.87596222e-01,\n",
       "         1.42625733e-01,   2.33920670e-01,   1.00311469e-01,\n",
       "         5.51173599e-01,   1.10685388e-01,   9.99321231e-02,\n",
       "         7.40761754e-01,   8.38322051e-01,   1.84838880e-01,\n",
       "         8.20082133e-02,   4.38310041e-01,   5.68352811e-01,\n",
       "         6.54850883e-01,   1.73494143e-01,   2.78789437e-01,\n",
       "         9.99422063e-01,   5.41637159e-01,   6.51723779e-01,\n",
       "         2.29443014e-01,   2.49895356e-01,   6.14309267e-01,\n",
       "         1.56526184e-01,   8.24648563e-02,   7.75203244e-01,\n",
       "         1.00455620e-01,   5.74587596e-01,   8.48911918e-01,\n",
       "         4.01491097e-01,   6.95231406e-01,   2.93431728e-01,\n",
       "         1.42783196e-01,   6.53186829e-02,   4.69067044e-01,\n",
       "         3.47380958e-01,   1.00417686e-01,   1.42625733e-01,\n",
       "         2.11259883e-01,   9.10586203e-01,   6.38683065e-01,\n",
       "         1.84838880e-01,   3.15580226e-01,   6.97352318e-02,\n",
       "         3.28969806e-01,   1.47092395e-01,   1.00417686e-01,\n",
       "         4.45823157e-02,   2.55795330e-01,   2.66488300e-01,\n",
       "         1.84823706e-01,   7.21311492e-01,   9.99321231e-02,\n",
       "         4.55610275e-02,   6.66573702e-01,   8.48667863e-01,\n",
       "         6.49839083e-01,   4.47620506e-01,   1.95527010e-01,\n",
       "         5.74763031e-02,   1.43051921e-01,   7.51772051e-01,\n",
       "        -9.49953962e-03,   2.55795330e-01,  -2.84486204e-02,\n",
       "         3.98091224e-01,   4.95855469e-01,   4.67090315e-01,\n",
       "         8.96914931e-01,   2.98428861e-01,   9.42811948e-02,\n",
       "         1.63296319e-01,   6.53186829e-02,   1.49024049e-01,\n",
       "         2.75022255e-01,   2.30674701e-01,   1.49509612e-01,\n",
       "         1.46608863e-01,   8.15501684e-01,   1.04696705e-01,\n",
       "         9.51070034e-01,   1.30945852e-01,   1.74427333e-01,\n",
       "         7.39311840e-01,   6.90146594e-01,   5.57639984e-01,\n",
       "         1.05371580e+00,   5.49627293e-01,   7.07843415e-01,\n",
       "         4.32173551e-01,   1.15339822e-01,   1.48231484e-01,\n",
       "         1.84838880e-01,   1.00417686e-01,   3.89058790e-01,\n",
       "         8.04050483e-01,   1.30763766e-01,   3.26251142e-01,\n",
       "         7.36866917e-01,   1.94792910e-01,   6.91669828e-01,\n",
       "         8.19146212e-02,   9.72053601e-01,   1.43279529e-01,\n",
       "         1.42218589e-01,   8.84601029e-01,   1.42221139e-01,\n",
       "         1.14269236e-01,   6.38683065e-01,   5.50668511e-01,\n",
       "         3.89769089e-02,   1.92646592e-01,   8.78026631e-01,\n",
       "         1.42221139e-01,   1.51243265e-01,   6.12217060e-01,\n",
       "         6.00033987e-01,   9.47176968e-01,   2.94461486e-01,\n",
       "         9.83004018e-01,   8.68403310e-02,   1.05679855e+00,\n",
       "         9.23971544e-01,   5.69657781e-01,   5.56715548e-01,\n",
       "         1.71378948e-01,   2.74694147e-01,   1.71384198e-01,\n",
       "         7.81508360e-01,   2.88052606e-01,   2.69920391e-02,\n",
       "         3.46687725e-01,   5.77220915e-01,   2.56617174e-01,\n",
       "         1.79631299e-01,   1.77630501e-01,   6.56601387e-01,\n",
       "         1.84452513e-01,   7.98322118e-01,   4.91231560e-01,\n",
       "         8.36120873e-01,   5.15329581e-01,   1.79613143e-01,\n",
       "         1.41440878e-02,   2.47280521e-01,   8.53617135e-02,\n",
       "         6.11366617e-01,   1.56428140e-02,   1.50037525e-01,\n",
       "         6.84503024e-01,   1.32333652e-01,   6.59034796e-02,\n",
       "         2.65748463e-02,   6.68647014e-01,   3.52664278e-01,\n",
       "         7.05618047e-01,   1.69486222e-01,   1.51551491e-01,\n",
       "         7.34344106e-01,   8.13138722e-01,   6.07113130e-01,\n",
       "         6.59197100e-02,   7.61136265e-01,   8.90440990e-01,\n",
       "         8.18970414e-02,   4.02973606e-01,   1.32673688e-01,\n",
       "         1.04243459e+00,   1.24673180e-01,   2.21279475e-01,\n",
       "         1.30659526e-01,   8.53617135e-02,   4.63229675e-02,\n",
       "         7.81301725e-01,  -3.13017696e-02,   7.40693305e-01,\n",
       "         1.39023368e-01,   8.40969695e-03,   7.71284547e-01,\n",
       "        -4.59060135e-02,   1.32332689e-01,   2.69818697e-01,\n",
       "         7.14037006e-01,   8.53263642e-02,   4.01632844e-01,\n",
       "        -1.17050270e-02,   4.06332748e-01,  -1.10994223e-02,\n",
       "         7.88552482e-02,   4.11847084e-01,   8.47901794e-01,\n",
       "         8.81915775e-01,   5.86785126e-01,   8.51324704e-02,\n",
       "         6.54512034e-01,   1.79613143e-01,   4.65350173e-02,\n",
       "         7.93168516e-01,   1.91168095e-02,   5.79742725e-01,\n",
       "         8.46210243e-01,   2.59535024e-01,   9.40495188e-02,\n",
       "         2.66953469e-01,   1.57180111e-01,   1.37085756e-01,\n",
       "         1.38976048e-01,   1.92246545e-01,   1.53674729e-01,\n",
       "         9.87558168e-01,   1.04739712e-01,   1.79609315e-01,\n",
       "         6.87633132e-02,  -5.72311195e-02,   4.26651606e-01,\n",
       "         3.91912940e-01,   6.21766731e-01,   7.73170802e-01,\n",
       "         6.59197100e-02,   1.95445004e-01,   6.28654047e-01,\n",
       "         3.43244736e-02,   1.43556872e-01,   1.01332007e+00,\n",
       "         6.67064544e-01,   9.64675751e-02,   7.55677508e-01,\n",
       "         2.80828824e-01,   1.50037525e-01,   2.72491036e-01,\n",
       "         8.52470919e-02,   6.50078692e-01,   8.53263642e-02,\n",
       "         8.57712022e-01,   1.37218511e-01,   7.05636203e-01,\n",
       "         7.76571080e-01,   1.81154274e-01,   8.53263642e-02,\n",
       "         6.52636315e-01,   2.79521479e-01,   3.12453438e-01,\n",
       "         1.80892541e-01,   6.11504129e-02,   2.81298607e-01,\n",
       "         3.99368547e-02,   9.06904562e-02,   1.29385345e-01,\n",
       "         2.66579247e-01,   8.52986716e-02,  -5.23391101e-03,\n",
       "         8.76955835e-01,   6.66132712e-01,   3.38008699e-01,\n",
       "        -2.51940819e-02,   2.27752551e-01,   2.37714624e-01,\n",
       "         1.56480948e-01,   1.14481736e-01,   6.82959628e-01,\n",
       "         5.82020213e-01,   5.28760753e-01,   7.05706878e-01,\n",
       "         4.69604907e-01,   1.43871118e-01,  -3.80034270e-02,\n",
       "         1.07054876e-02,   3.02483543e-01,  -4.31182533e-03,\n",
       "         1.50559052e-01,   1.56485716e-01,   1.07449874e+00,\n",
       "         3.39154914e-01,   8.39072527e-01,   9.64675751e-02,\n",
       "         1.58217153e-01,   1.97394745e-01,   9.19737357e-02,\n",
       "        -1.17050270e-02,   7.05614218e-01,   2.99724927e-01,\n",
       "         1.14550782e-03,   1.03553609e+00,   3.59112470e-01,\n",
       "         7.48714742e-01,   2.05495705e-01,   5.18475296e-02,\n",
       "         1.78963782e-01,   6.63276451e-01,   3.13814658e-01,\n",
       "         9.97957436e-01,   9.88263847e-02,   1.00878202e+00,\n",
       "         3.97999342e-01,   2.27999727e-01,   9.98546543e-02,\n",
       "         1.59432735e-01,   1.51487612e-01,   9.67647877e-01,\n",
       "         7.94440674e-01,   1.82354398e-01,   7.90818617e-02,\n",
       "         8.78743984e-01,   1.28889968e-01,   2.52533715e-01,\n",
       "         1.69777288e-01,   4.36159222e-01,   1.46364935e-01,\n",
       "         6.80699186e-01,   6.87797621e-01,   2.66808037e-01,\n",
       "         5.93377905e-01,   9.72302878e-01,   2.34513926e-01,\n",
       "         2.77758257e-01,   3.09428759e-01,   3.09428759e-01,\n",
       "         1.02764930e-01,   3.99461089e-01,   4.91293149e-01,\n",
       "         9.97768862e-02,   9.97768862e-02,   4.57596060e-01,\n",
       "         3.90870168e-01,   9.40624333e-01,   9.31271655e-02,\n",
       "         8.94337632e-02,   1.89211480e-01,   1.09291952e-01,\n",
       "         7.79046313e-01,   4.77537436e-01,   1.71630189e-01,\n",
       "         8.55685649e-01,   1.93546849e-01,   7.91663657e-02,\n",
       "         1.30810546e-01,   6.04746236e-01,   3.66669443e-01,\n",
       "         1.04944264e-01,   3.35216661e-01,   7.39230566e-02,\n",
       "         9.45498256e-01,   1.00100411e-01,   3.76718061e-02,\n",
       "         1.87397220e-01,   8.47876055e-01,   1.67010565e-01,\n",
       "         8.19065826e-01,   4.99168842e-01,   6.80039818e-01,\n",
       "         1.49865132e-01,   8.42829187e-02,   1.25716856e-01,\n",
       "         1.50159113e-03,   6.39272373e-01,   1.40846524e-01,\n",
       "         5.46238362e-01,   1.56664787e-01,   1.81974742e-01,\n",
       "         7.29959343e-01,   1.81974130e-01,   8.74474278e-01,\n",
       "         7.29426648e-01,   9.93896533e-01,   4.57596060e-01,\n",
       "         1.67923897e-02,   1.20424559e-01,   1.20434357e-01,\n",
       "         6.62475826e-01,   1.34570901e-01,   1.61475297e-01,\n",
       "         4.13180056e-01,   1.81974742e-01,   3.46271537e-01,\n",
       "         2.94483149e-01,   4.98732645e-01,   1.20465993e-01,\n",
       "         2.26672332e-01,   8.59774598e-01,   5.95294402e-01,\n",
       "         1.35674453e-01,   5.42894622e-01,   2.52533715e-01,\n",
       "         7.16193389e-01,   4.71359481e-01,   2.63316743e-01,\n",
       "         1.10076332e-01,   8.94264151e-02,   4.04403659e-01,\n",
       "         6.62489503e-01,   2.26672332e-01,   9.10949053e-01,\n",
       "         1.15293310e-01,   4.88503769e-02,   2.47238969e-01,\n",
       "         5.43222545e-01,   9.20260251e-02,   4.56126426e-01,\n",
       "         6.36635468e-01,   2.51999221e-01,   2.72941859e-02,\n",
       "         4.94576227e-02,   7.89238177e-01,   1.10158999e-01,\n",
       "         4.09575936e-01,   5.90752529e-01,   8.39169965e-02,\n",
       "         1.81935552e-01,   1.02157694e-01,   4.14663806e-01,\n",
       "         1.81974742e-01,   7.95183811e-01,   6.86523022e-01,\n",
       "         3.66050077e-01,   1.40846730e-01,   1.30808508e-01,\n",
       "         1.56691731e-01,   8.97073656e-01,   1.41192659e-01,\n",
       "         9.97844401e-02,   8.66408635e-02,   4.98683863e-01,\n",
       "         1.46328807e-01,   3.45512226e-01,   9.99398762e-01,\n",
       "         1.12360425e-01,   1.61881765e-01,   3.25203492e-02,\n",
       "        -2.11340342e-01,   1.09845725e-01,   2.59130405e-01,\n",
       "         9.74504426e-01,   4.77436068e-02,  -1.32981483e-01,\n",
       "         6.92178735e-01,   1.00570291e+00,   6.74358271e-01,\n",
       "         6.37149933e-01,   8.28940212e-01,   3.43636965e-01,\n",
       "         5.96870705e-01,   1.40846730e-01,  -2.78121172e-02,\n",
       "         2.86786821e-01,   8.64946875e-01,   2.94483149e-01,\n",
       "         3.04256482e-01,   7.16978993e-01,   8.02794679e-01,\n",
       "         4.48255551e-01,   9.98554724e-02,   1.70912665e-01,\n",
       "         1.15293716e-01,   8.13093716e-01,   4.35682258e-01,\n",
       "         6.72999806e-03,   7.98119222e-01,   7.19081889e-01,\n",
       "         1.46422903e-01,   1.51499653e-01,   9.97768862e-02,\n",
       "         8.42057962e-01,   7.80127812e-01,   7.90877794e-02,\n",
       "         6.41934706e-01,   2.83444906e-01,   1.20424559e-01,\n",
       "         5.10038949e-01,   2.88739652e-01,   1.01514232e+00,\n",
       "         5.22615881e-01,   5.14215390e-01,   1.66457912e-01])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_score=np.concatenate(pred_score,axis=0)\n",
    "\n",
    "pred_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891,)\n",
      "(891,)\n",
      "accuracy_linear_regression is : 0.787878787879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzpp220/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:6: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n",
      "/home/zzpp220/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:8: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"
     ]
    }
   ],
   "source": [
    "#将结果数组中的概率值映射为输出。0,1.在设置阈值为0.5\n",
    "threshold=0.5\n",
    "pred_score[pred_score>threshold]=1\n",
    "pred_score[pred_score<=threshold]=0\n",
    "print pred_score.shape\n",
    "print pred_score[pred_score==tanic[\"Survived\"]].shape\n",
    "\n",
    "accuracy=sum(pred_score[pred_score==tanic[\"Survived\"]])/len(pred_score)#最后的结果为均值\n",
    "print \"accuracy_linear_regression is :\",accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_logistic_regression is :0.789%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"用逻辑回归，同时交叉验证用更方便的表示\"\"\"\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "#cross_val_score(estimator, X, y=None, scoring=None, cv=None, n_jobs=1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model=LogisticRegression()\n",
    "# Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)\n",
    "log_sysout=cross_val_score(log_model,tanic[features],tanic[\"Survived\"],cv=5)#同样有5个元素\n",
    "print \"accuracy_logistic_regression is :{0:.3f}%\".format(log_sysout.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_random_forest is :80.592% \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "改用随机森林，综合利用特征，防止过拟合\n",
    "\"\"\"\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "# Initialize our algorithm with the default paramters\n",
    "# n_estimators is the number of trees we want to make,随机数设置为10\n",
    "# min_samples_split is 分裂一个中间结点的最小样本数，即只要该结点下的样本数大于=2就等继续分裂。#每棵树结点分裂的终止条件\n",
    "# min_samples_leaf is 叶子结点中的最小样本数 (the bottom points of the tree)\n",
    "ranforest_model=RandomForestClassifier(n_estimators=10,min_samples_split=2,min_samples_leaf=1)\n",
    "\n",
    "ranforest_sysout=cross_val_score(ranforest_model,tanic[features],tanic[\"Survived\"],cv=5,scoring=\"accuracy\")\n",
    "print \"accuracy_random_forest is :{0:.3f}% \".format(ranforest_sysout.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_random_forest--paramenter-modified is :83.062%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "在上述随机森林的分类器中调节参数,加大加深随机森林，结点分裂的终止条件宽松一点\n",
    "\"\"\"\n",
    "ranforest2_model=RandomForestClassifier(n_estimators=100,min_samples_split=5,min_samples_leaf=2)\n",
    "ranforest2_sysout=cross_val_score(ranforest2_model,tanic[features],tanic[\"Survived\"],cv=5,scoring=\"accuracy\")\n",
    "print \"accuracy_random_forest--paramenter-modified is :{0:.3f}%\".format(ranforest2_sysout.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzpp220/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     517\n",
      "2     183\n",
      "3     125\n",
      "4      40\n",
      "5       7\n",
      "6       6\n",
      "7       5\n",
      "10      3\n",
      "8       3\n",
      "9       2\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "------------------------------------------------------------------------------------------------------\n",
    "以上是基于样本数据的原始特征应用线性回归、逻辑回归、随机森林等方法进行预测是否被救的可能性\n",
    "但是实际问题中数据挖掘往往要建立以个特征工程：即在原始特征的基础上进行选择、抽取、组合出新的特征，更加综合，再进行预测\n",
    "\"\"\"\n",
    "#1.由兄弟姐妹、父母孩子的个数可知该家庭的总人数，可能也会影响最后获救与否，人多力量大？--生成一个家庭总人数的新特征：\n",
    "tanic[\"FamilySize\"]=tanic[\"SibSp\"]+tanic[\"Parch\"]\n",
    "\n",
    "#2.从样本名字中提取新特征--可能达官贵人的名字都比较长？-----生成一个样本名字长度的新特征\n",
    "tanic[\"NameLength\"]=tanic[\"Name\"].apply(lambda x:len(x))#对该列的每一个值求名字长度\n",
    "\n",
    "#3.样本名字中的称谓可能叶影响-----生成获取样本名称中对应称谓的新特征\n",
    "import re\n",
    "#----------------------------------------------------------------------------------\n",
    "#定义函数，用正则表达式获取名字中的称谓\n",
    "def gettitle(name):\n",
    "    title_search=re.search('([A-Za-z]+)\\.',name)#捕获一个子表达式\n",
    "    #注意 search和findall 不一样，search是找到一个就好了。findall是找到模式匹配的全部\n",
    "    title_findall=re.findall('([A-Za-z]+)\\.',name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)#返回捕获的表达式\n",
    "    return \"\"\n",
    "#----------------------------------------------------------------------------------\n",
    "tanic[\"Title\"]=tanic[\"Name\"].apply(gettitle)\n",
    "tanic[\"Title\"].value_counts(dropna=False)#查看该特征的取值\n",
    "#将特征的取值做数值转换\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\n",
    "for k,v in title_mapping.items():\n",
    "    tanic[\"Title\"][tanic[\"Title\"]==k]=v\n",
    "    #tanic.loc[tanic[\"Title\"==k],\"Title\"]=v #会报错\n",
    "print tanic[\"Title\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#\\xe7\\x8e\\xb0\\xe5\\x9c\\xa8\\xe6\\x9c\\x89\\xe7\\x9a\\x84\\xe6\\x89\\x80\\xe6\\x9c\\x89\\xe7\\x9a\\x84\\xe7\\x89\\xb9\\xe5\\xbe\\x81\\xe5\\xa6\\x82\\xe4\\xb8\\x8b:features \\nfeatures=['Pclass','Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'FamilySize', 'NameLength', 'Title']\\n\\n\\xe6\\x8e\\xa5\\xe4\\xb8\\x8b\\xe6\\x9d\\xa5\\xe8\\xa6\\x81\\xe5\\xaf\\xb9\\xe7\\x89\\xb9\\xe5\\xbe\\x81\\xe8\\xbf\\x9b\\xe8\\xa1\\x8c\\xe8\\xa1\\xa1\\xe9\\x87\\x8f\\xef\\xbc\\x8c\\xe9\\x82\\xa3\\xe4\\xba\\x9b\\xe7\\x89\\xb9\\xe5\\xbe\\x81\\xe6\\x9c\\x89\\xe7\\x94\\xa8\\xef\\xbc\\x8c\\xe6\\x9c\\x89\\xe7\\x94\\xa8\\xe7\\x9a\\x84\\xe7\\xa8\\x8b\\xe5\\xba\\xa6\\xe6\\x98\\xaf\\xe5\\xa4\\x9a\\xe5\\xb0\\x91\\xef\\xbc\\x8c\\xe9\\x82\\xa3\\xe4\\xba\\x9b\\xe6\\xb2\\xa1\\xe7\\x94\\xa8\\xef\\xbc\\x9f\\xe5\\xaf\\xb9\\xe7\\x89\\xb9\\xe5\\xbe\\x81\\xe8\\xbf\\x9b\\xe8\\xa1\\x8c\\xe9\\x80\\x89\\xe6\\x8b\\xa9\\xef\\xbc\\x8c\\xe9\\x80\\x89\\xe5\\x87\\xba\\xe5\\xbd\\xb1\\xe5\\x93\\x8d\\xe6\\x9c\\x80\\xe5\\xa4\\xa7\\xe7\\x9a\\x84\\xe5\\x87\\xa0\\xe4\\xb8\\xaa\\xe7\\x89\\xb9\\xe5\\xbe\\x81\\xef\\xbc\\x8c\\xe9\\x83\\xbd\\xe7\\x94\\xa8feature_importance\\xe9\\x87\\x8f\\xe5\\x8c\\x96\\xe6\\x9f\\xa5\\xe7\\x9c\\x8b\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.extend([\"FamilySize\",\"NameLength\",\"Title\"])\n",
    "\"\"\"#现在有的所有的特征如下:features \n",
    "features=['Pclass','Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'FamilySize', 'NameLength', 'Title']\n",
    "\n",
    "接下来要对特征进行衡量，那些特征有用，有用的程度是多少，那些没用？对特征进行选择，选出影响最大的几个特征，都用feature_importance量化查看\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.53704739e-25   1.40606613e-69   4.30004011e-02   2.92243929e-01\n",
      "   1.47992454e-02   6.12018934e-15   1.40831242e-03   6.19891122e-01\n",
      "   2.02679507e-24   1.03899613e-27] [  1.15031272e+02   3.72405724e+02   4.10714781e+00   1.11057220e+00\n",
      "   5.96346384e+00   6.30307642e+01   1.02593551e+01   2.46193112e-01\n",
      "   1.10388690e+02   1.27425897e+02]\n",
      "[ 24.59567142  68.85199425   1.36652749   0.5342545    1.82976043\n",
      "  14.21323514   2.85130099   0.20768458  23.69319016  26.98338607]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif#\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "help(SelectKBest)\n",
    "Parameters\n",
    " |  ----------\n",
    " |  score_func : callable\n",
    " |      Function taking two arrays X and y, and returning a pair of arrays\n",
    " |      (scores, pvalues) or a single array with scores.\n",
    " |      Default is f_classif (see below \"See also\"). The default function only\n",
    " |      works with classification tasks.\n",
    " |  \n",
    " |  k : int or \"all\", optional, default=10\n",
    " |      Number of top features to select.\n",
    " |      The \"all\" option bypasses selection, for use in a parameter search.\n",
    " |  \n",
    "Attributes\n",
    " |  ----------\n",
    " |  scores_ : array-like, shape=(n_features,)\n",
    " |      Scores of features.\n",
    " |  \n",
    " |  pvalues_ : array-like, shape=(n_features,)\n",
    " |      p-values of feature scores, None if `score_func` returned only scores.\n",
    " |  \n",
    "\n",
    "\"\"\"\n",
    "fea_selector=SelectKBest(f_classif,k=5)\n",
    "fea_selector.fit(tanic[features],tanic[\"Survived\"])\n",
    "# Get the raw p-values for each feature, and \n",
    "print fea_selector.pvalues_,fea_selector.scores_ #总共10个特征，得到没分特征的原始P-value\n",
    "scores = -np.log10(fea_selector.pvalues_)#transform from p-values into scores\n",
    "print scores#这个score不是scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scores反映了每个特征在该分类问题的中的影响程度，用画图的方式开看更直观些\n",
    "# Plot the scores.\n",
    "plt.bar(range(len(features)),scores)#选择条形图。横坐标定为1-10，纵坐标对应为特征取值\n",
    "plt.xticks(range(len(features)), features, rotation='vertical')#更改横坐标各个点代表的标签值\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_top_random_forest--paramenter-modified is :81.710%\n"
     ]
    }
   ],
   "source": [
    "# from the chart,Pick only the top5 features.\n",
    "top5_fea = [ \"Sex\",\"Pclass\", \"Title\",\"NameLength\",\"Fare\"]\n",
    "#重新用该特征组合 运用随机森林\n",
    "top_ranforest_model=RandomForestClassifier(n_estimators=100,min_samples_split=4,min_samples_leaf=2,random_state=1)\n",
    "top_ranforest_sysout=cross_val_score(top_ranforest_model,tanic[top5_fea],tanic[\"Survived\"],cv=5,scoring=\"accuracy\")\n",
    "print \"accuracy_top_random_forest--paramenter-modified is :{0:.3f}%\".format(top_ranforest_sysout.mean()*100)\n",
    "#由结果可知，和之前的随机森林结果82.724相比，虽然差一点但很微小，但是特征的维度减低了一半啊，计算复杂度降低了，很实用的一个功能！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "使用集成学习的迭代决策树\n",
    "特征不仅可以组合，也可以考虑将分类算法进行集成，综合多个分类器的优缺点\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GradientBoostingClassifier in module sklearn.ensemble.gradient_boosting:\n",
      "\n",
      "class GradientBoostingClassifier(BaseGradientBoosting, sklearn.base.ClassifierMixin)\n",
      " |  Gradient Boosting for classification.\n",
      " |  \n",
      " |  GB builds an additive model in a\n",
      " |  forward stage-wise fashion; it allows for the optimization of\n",
      " |  arbitrary differentiable loss functions. In each stage ``n_classes_``\n",
      " |  regression trees are fit on the negative gradient of the\n",
      " |  binomial or multinomial deviance loss function. Binary classification\n",
      " |  is a special case where only a single regression tree is induced.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <gradient_boosting>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  loss : {'deviance', 'exponential'}, optional (default='deviance')\n",
      " |      loss function to be optimized. 'deviance' refers to\n",
      " |      deviance (= logistic regression) for classification\n",
      " |      with probabilistic outputs. For loss 'exponential' gradient\n",
      " |      boosting recovers the AdaBoost algorithm.\n",
      " |  \n",
      " |  learning_rate : float, optional (default=0.1)\n",
      " |      learning rate shrinks the contribution of each tree by `learning_rate`.\n",
      " |      There is a trade-off between learning_rate and n_estimators.\n",
      " |  \n",
      " |  n_estimators : int (default=100)\n",
      " |      The number of boosting stages to perform. Gradient boosting\n",
      " |      is fairly robust to over-fitting so a large number usually\n",
      " |      results in better performance.\n",
      " |  \n",
      " |  max_depth : integer, optional (default=3)\n",
      " |      maximum depth of the individual regression estimators. The maximum\n",
      " |      depth limits the number of nodes in the tree. Tune this parameter\n",
      " |      for best performance; the best value depends on the interaction\n",
      " |      of the input variables.\n",
      " |  \n",
      " |  criterion : string, optional (default=\"friedman_mse\")\n",
      " |      The function to measure the quality of a split. Supported criteria\n",
      " |      are \"friedman_mse\" for the mean squared error with improvement\n",
      " |      score by Friedman, \"mse\" for mean squared error, and \"mae\" for\n",
      " |      the mean absolute error. The default value of \"friedman_mse\" is\n",
      " |      generally the best as it can provide a better approximation in\n",
      " |      some cases.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |  \n",
      " |  min_samples_split : int, float, optional (default=2)\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a percentage and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for percentages.\n",
      " |  \n",
      " |  min_samples_leaf : int, float, optional (default=1)\n",
      " |      The minimum number of samples required to be at a leaf node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a percentage and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for percentages.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, optional (default=0.)\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  subsample : float, optional (default=1.0)\n",
      " |      The fraction of samples to be used for fitting the individual base\n",
      " |      learners. If smaller than 1.0 this results in Stochastic Gradient\n",
      " |      Boosting. `subsample` interacts with the parameter `n_estimators`.\n",
      " |      Choosing `subsample < 1.0` leads to a reduction of variance\n",
      " |      and an increase in bias.\n",
      " |  \n",
      " |  max_features : int, float, string or None, optional (default=None)\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a percentage and\n",
      " |        `int(max_features * n_features)` features are considered at each\n",
      " |        split.\n",
      " |      - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Choosing `max_features < n_features` leads to a reduction of variance\n",
      " |      and an increase in bias.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  max_leaf_nodes : int or None, optional (default=None)\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_split : float, optional (default=1e-7)\n",
      " |      Threshold for early stopping in tree growth. A node will split\n",
      " |      if its impurity is above the threshold, otherwise it is a leaf.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |  \n",
      " |  init : BaseEstimator, None, optional (default=None)\n",
      " |      An estimator object that is used to compute the initial\n",
      " |      predictions. ``init`` has to provide ``fit`` and ``predict``.\n",
      " |      If None it uses ``loss.init_estimator``.\n",
      " |  \n",
      " |  verbose : int, default: 0\n",
      " |      Enable verbose output. If 1 then it prints progress and performance\n",
      " |      once in a while (the more trees the lower the frequency). If greater\n",
      " |      than 1 then it prints progress and performance for every tree.\n",
      " |  \n",
      " |  warm_start : bool, default: False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just erase the\n",
      " |      previous solution.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  presort : bool or 'auto', optional (default='auto')\n",
      " |      Whether to presort the data to speed up the finding of best splits in\n",
      " |      fitting. Auto mode by default will use presorting on dense data and\n",
      " |      default to normal sorting on sparse data. Setting presort to true on\n",
      " |      sparse data will raise an error.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *presort* parameter.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  feature_importances_ : array, shape = [n_features]\n",
      " |      The feature importances (the higher, the more important the feature).\n",
      " |  \n",
      " |  oob_improvement_ : array, shape = [n_estimators]\n",
      " |      The improvement in loss (= deviance) on the out-of-bag samples\n",
      " |      relative to the previous iteration.\n",
      " |      ``oob_improvement_[0]`` is the improvement in\n",
      " |      loss of the first stage over the ``init`` estimator.\n",
      " |  \n",
      " |  train_score_ : array, shape = [n_estimators]\n",
      " |      The i-th score ``train_score_[i]`` is the deviance (= loss) of the\n",
      " |      model at iteration ``i`` on the in-bag sample.\n",
      " |      If ``subsample == 1`` this is the deviance on the training data.\n",
      " |  \n",
      " |  loss_ : LossFunction\n",
      " |      The concrete ``LossFunction`` object.\n",
      " |  \n",
      " |  init : BaseEstimator\n",
      " |      The estimator that provides the initial predictions.\n",
      " |      Set via the ``init`` argument or ``loss.init_estimator``.\n",
      " |  \n",
      " |  estimators_ : ndarray of DecisionTreeRegressor, shape = [n_estimators, ``loss_.K``]\n",
      " |      The collection of fitted sub-estimators. ``loss_.K`` is 1 for binary\n",
      " |      classification, otherwise n_classes.\n",
      " |  \n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  sklearn.tree.DecisionTreeClassifier, RandomForestClassifier\n",
      " |  AdaBoostClassifier\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  J. Friedman, Greedy Function Approximation: A Gradient Boosting\n",
      " |  Machine, The Annals of Statistics, Vol. 29, No. 5, 2001.\n",
      " |  \n",
      " |  J. Friedman, Stochastic Gradient Boosting, 1999\n",
      " |  \n",
      " |  T. Hastie, R. Tibshirani and J. Friedman.\n",
      " |  Elements of Statistical Learning Ed. 2, Springer, 2009.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GradientBoostingClassifier\n",
      " |      BaseGradientBoosting\n",
      " |      abc.NewBase\n",
      " |      sklearn.ensemble.base.BaseEnsemble\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.feature_selection.from_model._LearntSelectorMixin\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_split=1e-07, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort='auto')\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Compute the decision function of ``X``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape = [n_samples, n_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : array, shape = [n_samples, n_classes] or [n_samples]\n",
      " |          The decision function of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |          Regression and binary classification produce an array of shape\n",
      " |          [n_samples].\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class for X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape = [n_samples, n_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y: array of shape = [\"n_samples]\n",
      " |          The predicted values.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities for X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape = [n_samples, n_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AttributeError\n",
      " |          If the ``loss`` does not support probabilities.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples]\n",
      " |          The class log-probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape = [n_samples, n_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AttributeError\n",
      " |          If the ``loss`` does not support probabilities.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples]\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  staged_decision_function(self, X)\n",
      " |      Compute decision function of ``X`` for each iteration.\n",
      " |      \n",
      " |      This method allows monitoring (i.e. determine error on testing set)\n",
      " |      after each stage.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape = [n_samples, n_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : generator of array, shape = [n_samples, k]\n",
      " |          The decision function of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |          Regression and binary classification are special cases with\n",
      " |          ``k == 1``, otherwise ``k==n_classes``.\n",
      " |  \n",
      " |  staged_predict(self, X)\n",
      " |      Predict class at each stage for X.\n",
      " |      \n",
      " |      This method allows monitoring (i.e. determine error on testing set)\n",
      " |      after each stage.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape = [n_samples, n_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : generator of array of shape = [n_samples]\n",
      " |          The predicted value of the input samples.\n",
      " |  \n",
      " |  staged_predict_proba(self, X)\n",
      " |      Predict class probabilities at each stage for X.\n",
      " |      \n",
      " |      This method allows monitoring (i.e. determine error on testing set)\n",
      " |      after each stage.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape = [n_samples, n_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : generator of array of shape = [n_samples]\n",
      " |          The predicted value of the input samples.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset([])\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseGradientBoosting:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the ensemble to X, return leaf indices.\n",
      " |      \n",
      " |      .. versionadded:: 0.17\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will\n",
      " |          be converted to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array_like, shape = [n_samples, n_estimators, n_classes]\n",
      " |          For each datapoint x in X and for each tree in the ensemble,\n",
      " |          return the index of the leaf x ends up in each estimator.\n",
      " |          In the case of binary classification n_classes is 1.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, monitor=None)\n",
      " |      Fit the gradient boosting model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |          Training vectors, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples]\n",
      " |          Target values (integers in classification, real numbers in\n",
      " |          regression)\n",
      " |          For classification, labels must correspond to classes.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples] or None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      monitor : callable, optional\n",
      " |          The monitor is called after each iteration with the current\n",
      " |          iteration, a reference to the estimator and the local variables of\n",
      " |          ``_fit_stages`` as keyword arguments ``callable(i, self,\n",
      " |          locals())``. If the callable returns ``True`` the fitting procedure\n",
      " |          is stopped. The monitor can be used for various things such as\n",
      " |          computing held-out estimates, early stopping, model introspect, and\n",
      " |          snapshoting.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseGradientBoosting:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Return the feature importances (the higher, the more important the\n",
      " |         feature).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array, shape = [n_features]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble.base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Returns the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Returns iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Returns the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.feature_selection.from_model._LearntSelectorMixin:\n",
      " |  \n",
      " |  transform(*args, **kwargs)\n",
      " |      DEPRECATED: Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      " |      \n",
      " |      Reduce X to its most important features.\n",
      " |      \n",
      " |              Uses ``coef_`` or ``feature_importances_`` to determine the most\n",
      " |              important features.  For models with a ``coef_`` for each class, the\n",
      " |              absolute sum over the classes is used.\n",
      " |      \n",
      " |              Parameters\n",
      " |              ----------\n",
      " |              X : array or scipy sparse matrix of shape [n_samples, n_features]\n",
      " |                  The input samples.\n",
      " |      \n",
      " |              threshold : string, float or None, optional (default=None)\n",
      " |                  The threshold value to use for feature selection. Features whose\n",
      " |                  importance is greater or equal are kept while the others are\n",
      " |                  discarded. If \"median\" (resp. \"mean\"), then the threshold value is\n",
      " |                  the median (resp. the mean) of the feature importances. A scaling\n",
      " |                  factor (e.g., \"1.25*mean\") may also be used. If None and if\n",
      " |                  available, the object attribute ``threshold`` is used. Otherwise,\n",
      " |                  \"mean\" is used by default.\n",
      " |      \n",
      " |              Returns\n",
      " |              -------\n",
      " |              X_r : array of shape [n_samples, n_selected_features]\n",
      " |                  The input samples with only the selected features.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array of shape [n_samples, n_features]\n",
      " |          Training set.\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GradientBoostingClassifier)\n",
    "ensemble_fea=[\"Pclass\",\"Sex\",\"Age\",\"Fare\",\"Title\",\"NameLength\",\"Embarked\"]\n",
    "#选定特征都要永在两种算法。\n",
    "gbrt_model=GradientBoostingClassifier(random_state=1,n_estimators=25,max_depth=3)\n",
    "lg_model=LogisticRegression(random_state=1)\n",
    "algorithm=[[gbrt_model,ensemble_fea],[lg_model,ensemble_fea]]#一行写不下分两行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_semble_gbrt_lg is :80.415%\n"
     ]
    }
   ],
   "source": [
    "#自己的方法\n",
    "score_gbrt=cross_val_score(gbrt_model,tanic[ensemble_fea],tanic[\"Survived\"],cv=5,scoring=\"accuracy\")\n",
    "score_lg=cross_val_score(lg_model,tanic[ensemble_fea],tanic[\"Survived\"],cv=5,scoring=\"accuracy\")\n",
    "score_ensemble=(score_gbrt+score_lg)/2\n",
    "print \"accuracy_semble_gbrt_lg is :{0:.3f}%\".format(score_ensemble.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>2.265550</td>\n",
       "      <td>30.272590</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>35.627188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>14.181209</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>55.907576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
       "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
       "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
       "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
       "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
       "25%     996.250000    1.000000         NaN    0.000000    0.000000         NaN\n",
       "50%    1100.500000    3.000000         NaN    0.000000    0.000000         NaN\n",
       "75%    1204.750000    3.000000         NaN    1.000000    0.000000         NaN\n",
       "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tanic=pd.read_csv(\"test.csv\")\n",
    "test_tanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name Sex  \\\n",
       "0          892       3                              Kelly, Mr. James   0   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)   1   \n",
       "2          894       2                     Myles, Mr. Thomas Francis   0   \n",
       "3          895       3                              Wirz, Mr. Albert   0   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   1   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#测试数据预处理\n",
    "test_tanic[\"Age\"]=test_tanic[\"Age\"].fillna(int(test_tanic[\"Age\"].mean()))\n",
    "test_tanic[\"Fare\"]=test_tanic[\"Fare\"].fillna(test_tanic[\"Fare\"].median())\n",
    "\n",
    "\n",
    "#定位SEX属性的行，并且做数值映射 ，替换原来的值.loc[row_indexer,col_indexer] = value instead\n",
    "\n",
    "test_tanic.loc[test_tanic[\"Sex\"]==\"male\",\"Sex\"]=0\n",
    "test_tanic.loc[test_tanic[\"Sex\"]==\"female\",\"Sex\"]=1\n",
    "test_tanic[\"Sex\"].unique()\n",
    "\n",
    "\n",
    "#看如下结果，修改完成\n",
    "test_tanic.head()\n",
    "#test_tanic[\"Fare\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#还有Embarked 列。代表登船地点，同样的方法处理\n",
    "#test_tanic.head()\n",
    "test_tanic[\"Embarked\"].unique()#array(['S', 'C', 'Q', nan], dtype=object)\n",
    "#发现有缺失值，首先进行填充，--看各其他取非nan值的分布--groupby\n",
    "test_tanic[\"Embarked\"].value_counts(dropna=False)#不要扔掉nan\n",
    "\n",
    "#test_tanic[\"Embarked\"]=test_tanic[\"Embarked\"].fillna(\"S\")#将填充后的列替换填充前的列\n",
    "#填充完缺失值再进行数值映射，替换原来的值\n",
    "test_tanic.loc[test_tanic[\"Embarked\"]==\"S\",\"Embarked\"]=0\n",
    "test_tanic.loc[test_tanic[\"Embarked\"]==\"C\",\"Embarked\"]=1\n",
    "test_tanic.loc[test_tanic[\"Embarked\"]==\"Q\",\"Embarked\"]=2\n",
    "test_tanic[\"FamilySize\"]=test_tanic[\"SibSp\"]+test_tanic[\"Parch\"]\n",
    "test_tanic[\"Embarked\"].unique()\n",
    "#test_tanic.head()\n",
    "#替换完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzpp220/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    240\n",
      "2     79\n",
      "3     72\n",
      "4     21\n",
      "7      2\n",
      "6      2\n",
      "9      1\n",
      "5      1\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "------------------------------------------------------------------------------------------------------\n",
    "以上是基于样本数据的原始特征应用线性回归、逻辑回归、随机森林等方法进行预测是否被救的可能性\n",
    "但是实际问题中数据挖掘往往要建立以个特征工程：即在原始特征的基础上进行选择、抽取、组合出新的特征，更加综合，再进行预测\n",
    "\"\"\"\n",
    "#1.由兄弟姐妹、父母孩子的个数可知该家庭的总人数，可能也会影响最后获救与否，人多力量大？--生成一个家庭总人数的新特征：\n",
    "#tanic[\"FamilySize\"]=tanic[\"SibSp\"]+tanic[\"Parch\"]\n",
    "\n",
    "#2.从样本名字中提取新特征--可能达官贵人的名字都比较长？-----生成一个样本名字长度的新特征\n",
    "test_tanic[\"NameLength\"]=test_tanic[\"Name\"].apply(lambda x:len(x))#对该列的每一个值求名字长度\n",
    "\n",
    "#3.样本名字中的称谓可能叶影响-----生成获取样本名称中对应称谓的新特征\n",
    "'''import re\n",
    "#----------------------------------------------------------------------------------\n",
    "#定义函数，用正则表达式获取名字中的称谓\n",
    "def gettitle(name):\n",
    "    title_search=re.search('([A-Za-z]+)\\.',name)#捕获一个子表达式\n",
    "    #注意 search和findall 不一样，search是找到一个就好了。findall是找到模式匹配的全部\n",
    "    title_findall=re.findall('([A-Za-z]+)\\.',name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)#返回捕获的表达式\n",
    "    return \"\"\n",
    "#----------------------------------------------------------------------------------\n",
    "'''\n",
    "test_tanic[\"Title\"]=test_tanic[\"Name\"].apply(gettitle)\n",
    "test_tanic[\"Title\"].value_counts(dropna=False)#查看该特征的取值\n",
    "#将特征的取值做数值转换\n",
    "test_title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Dona\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\n",
    "\n",
    "for k,v in test_title_mapping.items():\n",
    "    test_tanic[\"Title\"][test_tanic[\"Title\"]==k]=v\n",
    "    #tanic.loc[tanic[\"Title\"==k],\"Title\"]=v #会报错\n",
    "print test_tanic[\"Title\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ensemble_sysout=[]\n",
    "#视频中的方法\n",
    "for alg,fea in algorithm:\n",
    "    alg.fit(tanic[fea],tanic[\"Survived\"])\n",
    "     # Predict using the test dataset.  We have to convert all the columns to floats to avoid an error.\n",
    "    test_sysout=alg.predict_proba(test_tanic[fea].astype(float))[:,1]\n",
    "    ensemble_sysout.append(test_sysout)\n",
    "print len  (ensemble_sysout)#用了两种算法的原因\n",
    "fina_sysout=(ensemble_sysout[0]*3+ensemble_sysout[1])/4\n",
    "fina_proba=fina_sysout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.95      0.94       266\n",
      "          1       0.91      0.88      0.89       152\n",
      "\n",
      "avg / total       0.92      0.92      0.92       418\n",
      "\n",
      "[[252  14]\n",
      " [ 18 134]]\n"
     ]
    }
   ],
   "source": [
    "#将结果数组中的概率值映射为输出。0,1.在设置阈值为0.5\n",
    "#threshold=0.5\n",
    "fina_sysout[fina_sysout>threshold]=1\n",
    "fina_sysout[fina_sysout<=threshold]=0\n",
    "print type(fina_sysout)\n",
    "\n",
    "test_label=pd.read_csv(\"gender_submission.csv\")\n",
    "test_label=np.array(test_label[\"Survived\"])\n",
    "\n",
    "from sklearn import metrics\n",
    "print metrics.classification_report(test_label,fina_sysout)\n",
    "print metrics.confusion_matrix(test_label,fina_sysout)\n",
    "#accuracy=sum(fina_sysout[fina_sysout==test_label])/len(fina_sysout)\n",
    "\n",
    "#accuracy=sum(pred_score[pred_score==tanic[\"Survived\"]])/len(pred_score)#最后的结果为均值\n",
    "#print \"accuracy_linear_regression is :\",accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.914473684211\n",
      "auc:  0.914473684211\n"
     ]
    }
   ],
   "source": [
    "#回头看看auc,roc的值的情况\n",
    "from sklearn.metrics import roc_curve,auc,roc_auc_score\n",
    "\n",
    "print \"auc: \",roc_auc_score(test_label,fina_sysout)#\n",
    "print \"auc: \",roc_auc_score(test_label,fina_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function roc_auc_score in module sklearn.metrics.ranking:\n",
      "\n",
      "roc_auc_score(y_true, y_score, average='macro', sample_weight=None)\n",
      "    Compute Area Under the Curve (AUC) from prediction scores\n",
      "    \n",
      "    Note: this implementation is restricted to the binary classification task\n",
      "    or multilabel classification task in label indicator format.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <roc_metrics>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : array, shape = [n_samples] or [n_samples, n_classes]\n",
      "        True binary labels in binary label indicators.\n",
      "    \n",
      "    y_score : array, shape = [n_samples] or [n_samples, n_classes]\n",
      "        Target scores, can either be probability estimates of the positive\n",
      "        class, confidence values, or non-thresholded measure of decisions\n",
      "        (as returned by \"decision_function\" on some classifiers).\n",
      "    \n",
      "    average : string, [None, 'micro', 'macro' (default), 'samples', 'weighted']\n",
      "        If ``None``, the scores for each class are returned. Otherwise,\n",
      "        this determines the type of averaging performed on the data:\n",
      "    \n",
      "        ``'micro'``:\n",
      "            Calculate metrics globally by considering each element of the label\n",
      "            indicator matrix as a label.\n",
      "        ``'macro'``:\n",
      "            Calculate metrics for each label, and find their unweighted\n",
      "            mean.  This does not take label imbalance into account.\n",
      "        ``'weighted'``:\n",
      "            Calculate metrics for each label, and find their average, weighted\n",
      "            by support (the number of true instances for each label).\n",
      "        ``'samples'``:\n",
      "            Calculate metrics for each instance, and find their average.\n",
      "    \n",
      "    sample_weight : array-like of shape = [n_samples], optional\n",
      "        Sample weights.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    auc : float\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `Wikipedia entry for the Receiver operating characteristic\n",
      "            <https://en.wikipedia.org/wiki/Receiver_operating_characteristic>`_\n",
      "    \n",
      "    See also\n",
      "    --------\n",
      "    average_precision_score : Area under the precision-recall curve\n",
      "    \n",
      "    roc_curve : Compute Receiver operating characteristic (ROC)\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.metrics import roc_auc_score\n",
      "    >>> y_true = np.array([0, 0, 1, 1])\n",
      "    >>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
      "    >>> roc_auc_score(y_true, y_scores)\n",
      "    0.75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function auc in module sklearn.metrics.ranking:\n",
      "\n",
      "auc(x, y, reorder=False)\n",
      "    Compute Area Under the Curve (AUC) using the trapezoidal rule\n",
      "    \n",
      "    This is a general function, given points on a curve.  For computing the\n",
      "    area under the ROC-curve, see :func:`roc_auc_score`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array, shape = [n]\n",
      "        x coordinates.\n",
      "    \n",
      "    y : array, shape = [n]\n",
      "        y coordinates.\n",
      "    \n",
      "    reorder : boolean, optional (default=False)\n",
      "        If True, assume that the curve is ascending in the case of ties, as for\n",
      "        an ROC curve. If the curve is non-ascending, the result will be wrong.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    auc : float\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn import metrics\n",
      "    >>> y = np.array([1, 1, 2, 2])\n",
      "    >>> pred = np.array([0.1, 0.4, 0.35, 0.8])\n",
      "    >>> fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=2)\n",
      "    >>> metrics.auc(fpr, tpr)\n",
      "    0.75\n",
      "    \n",
      "    See also\n",
      "    --------\n",
      "    roc_auc_score : Computes the area under the ROC curve\n",
      "    \n",
      "    precision_recall_curve :\n",
      "        Compute precision-recall pairs for different probability thresholds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function roc_curve in module sklearn.metrics.ranking:\n",
      "\n",
      "roc_curve(y_true, y_score, pos_label=None, sample_weight=None, drop_intermediate=True)\n",
      "    Compute Receiver operating characteristic (ROC)\n",
      "    \n",
      "    Note: this implementation is restricted to the binary classification task.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <roc_metrics>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    \n",
      "    y_true : array, shape = [n_samples]\n",
      "        True binary labels in range {0, 1} or {-1, 1}.  If labels are not\n",
      "        binary, pos_label should be explicitly given.\n",
      "    \n",
      "    y_score : array, shape = [n_samples]\n",
      "        Target scores, can either be probability estimates of the positive\n",
      "        class, confidence values, or non-thresholded measure of decisions\n",
      "        (as returned by \"decision_function\" on some classifiers).\n",
      "    \n",
      "    pos_label : int or str, default=None\n",
      "        Label considered as positive and others are considered negative.\n",
      "    \n",
      "    sample_weight : array-like of shape = [n_samples], optional\n",
      "        Sample weights.\n",
      "    \n",
      "    drop_intermediate : boolean, optional (default=True)\n",
      "        Whether to drop some suboptimal thresholds which would not appear\n",
      "        on a plotted ROC curve. This is useful in order to create lighter\n",
      "        ROC curves.\n",
      "    \n",
      "        .. versionadded:: 0.17\n",
      "           parameter *drop_intermediate*.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    fpr : array, shape = [>2]\n",
      "        Increasing false positive rates such that element i is the false\n",
      "        positive rate of predictions with score >= thresholds[i].\n",
      "    \n",
      "    tpr : array, shape = [>2]\n",
      "        Increasing true positive rates such that element i is the true\n",
      "        positive rate of predictions with score >= thresholds[i].\n",
      "    \n",
      "    thresholds : array, shape = [n_thresholds]\n",
      "        Decreasing thresholds on the decision function used to compute\n",
      "        fpr and tpr. `thresholds[0]` represents no instances being predicted\n",
      "        and is arbitrarily set to `max(y_score) + 1`.\n",
      "    \n",
      "    See also\n",
      "    --------\n",
      "    roc_auc_score : Compute Area Under the Curve (AUC) from prediction scores\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Since the thresholds are sorted from low to high values, they\n",
      "    are reversed upon returning them to ensure they correspond to both ``fpr``\n",
      "    and ``tpr``, which are sorted in reversed order during their calculation.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `Wikipedia entry for the Receiver operating characteristic\n",
      "            <https://en.wikipedia.org/wiki/Receiver_operating_characteristic>`_\n",
      "    \n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn import metrics\n",
      "    >>> y = np.array([1, 1, 2, 2])\n",
      "    >>> scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
      "    >>> fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)\n",
      "    >>> fpr\n",
      "    array([ 0. ,  0.5,  0.5,  1. ])\n",
      "    >>> tpr\n",
      "    array([ 0.5,  0.5,  1. ,  1. ])\n",
      "    >>> thresholds\n",
      "    array([ 0.8 ,  0.4 ,  0.35,  0.1 ])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(roc_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12162225,  0.48772383,  0.11891431,  0.11772443,  0.54349687,\n",
       "        0.1310479 ,  0.61331407,  0.19454212,  0.7063859 ,  0.12441115,\n",
       "        0.11634258,  0.21853977,  0.91259616,  0.09742088,  0.90448876,\n",
       "        0.87754648,  0.15955972,  0.12949051,  0.49644922,  0.62813377,\n",
       "        0.22590665,  0.36896991,  0.90049095,  0.50201624,  0.91460642,\n",
       "        0.10482728,  0.91460807,  0.12834476,  0.29502843,  0.12340609,\n",
       "        0.12471476,  0.19846706,  0.51801514,  0.35212278,  0.35131959,\n",
       "        0.38329979,  0.46361052,  0.47936358,  0.1183162 ,  0.33074008,\n",
       "        0.11156452,  0.42045143,  0.10720293,  0.84605224,  0.90882524,\n",
       "        0.12577294,  0.31089926,  0.13715631,  0.90513413,  0.52121475,\n",
       "        0.33927603,  0.1609439 ,  0.84256592,  0.8960059 ,  0.20085515,\n",
       "        0.22363499,  0.10764952,  0.1246951 ,  0.11992135,  0.90884923,\n",
       "        0.12268923,  0.14598626,  0.12911936,  0.6699288 ,  0.77911605,\n",
       "        0.86691585,  0.66995049,  0.33735539,  0.468842  ,  0.88403002,\n",
       "        0.66266916,  0.12173245,  0.49566405,  0.47364208,  0.88805614,\n",
       "        0.34359421,  0.11634403,  0.85441117,  0.15322165,  0.65855782,\n",
       "        0.60126994,  0.17952625,  0.20892281,  0.1178083 ,  0.17877033,\n",
       "        0.12381207,  0.61591424,  0.49753535,  0.64928832,  0.70351295,\n",
       "        0.58005734,  0.11705835,  0.90242623,  0.11669865,  0.26918305,\n",
       "        0.12316559,  0.87040198,  0.12036785,  0.52458433,  0.11317022,\n",
       "        0.92261736,  0.14562565,  0.13282153,  0.15542603,  0.66016833,\n",
       "        0.12110002,  0.14221404,  0.13147958,  0.13004522,  0.15467759,\n",
       "        0.14257822,  0.6536086 ,  0.89507601,  0.69380935,  0.8742181 ,\n",
       "        0.13937869,  0.12271082,  0.66057653,  0.33431053,  0.86477286,\n",
       "        0.8434386 ,  0.13214429,  0.9125068 ,  0.12003622,  0.13214429,\n",
       "        0.51151839,  0.12405255,  0.56682155,  0.12582171,  0.12093001,\n",
       "        0.11799974,  0.44642305,  0.26156989,  0.12526776,  0.10677553,\n",
       "        0.12329204,  0.1301852 ,  0.14737398,  0.48010222,  0.14674583,\n",
       "        0.28494191,  0.88592081,  0.21491352,  0.15206412,  0.69698659,\n",
       "        0.11941386,  0.36391718,  0.12027005,  0.37060775,  0.30681216,\n",
       "        0.91986628,  0.12475615,  0.08658898,  0.5210638 ,  0.17634026,\n",
       "        0.12092396,  0.88877919,  0.51258013,  0.3478582 ,  0.52342965,\n",
       "        0.61034442,  0.4892634 ,  0.82279001,  0.1170507 ,  0.29669576,\n",
       "        0.51484851,  0.29791596,  0.1643153 ,  0.91407495,  0.49293006,\n",
       "        0.11705613,  0.12624252,  0.12350001,  0.12272118,  0.17724697,\n",
       "        0.85825666,  0.84578636,  0.31192677,  0.87017074,  0.898133  ,\n",
       "        0.14830188,  0.50669869,  0.92482538,  0.13214429,  0.92310615,\n",
       "        0.13128587,  0.84834564,  0.12419292,  0.22130105,  0.12418653,\n",
       "        0.13348742,  0.24079596,  0.4380721 ,  0.11379983,  0.6567145 ,\n",
       "        0.14035593,  0.81581944,  0.52689383,  0.16266857,  0.50688285,\n",
       "        0.58387796,  0.64377053,  0.50081154,  0.85429696,  0.15342466,\n",
       "        0.23698041,  0.64151644,  0.15900745,  0.89332269,  0.11951703,\n",
       "        0.11977936,  0.11668899,  0.19642245,  0.80908911,  0.50514535,\n",
       "        0.2911707 ,  0.65361244,  0.21005122,  0.91179155,  0.12255022,\n",
       "        0.85313512,  0.12367567,  0.83777797,  0.12747165,  0.90110325,\n",
       "        0.66429942,  0.12443871,  0.64783005,  0.10867301,  0.16836236,\n",
       "        0.20332319,  0.87919392,  0.12416475,  0.1342167 ,  0.33603574,\n",
       "        0.12431456,  0.20131977,  0.13157356,  0.83622703,  0.91120049,\n",
       "        0.88928541,  0.82742547,  0.37539388,  0.11705946,  0.22427919,\n",
       "        0.29579909,  0.85559915,  0.16339017,  0.85053327,  0.63899319,\n",
       "        0.81211   ,  0.16182376,  0.36044377,  0.12281877,  0.10997327,\n",
       "        0.12025311,  0.13082728,  0.119203  ,  0.83707596,  0.12470358,\n",
       "        0.13983694,  0.12747257,  0.86635665,  0.65645976,  0.20733813,\n",
       "        0.11819497,  0.33571692,  0.1206923 ,  0.47581703,  0.12369046,\n",
       "        0.37112024,  0.13147958,  0.92127308,  0.58387796,  0.12527917,\n",
       "        0.84872204,  0.15367126,  0.12850514,  0.14393732,  0.15846549,\n",
       "        0.48167704,  0.58087443,  0.61479412,  0.64314871,  0.65370863,\n",
       "        0.10849022,  0.15248981,  0.34327682,  0.12637686,  0.11634403,\n",
       "        0.48642569,  0.56349821,  0.12321217,  0.4562885 ,  0.11054824,\n",
       "        0.11983246,  0.82934437,  0.12340609,  0.31956083,  0.11790498,\n",
       "        0.11878685,  0.15788999,  0.13005191,  0.11963211,  0.66331831,\n",
       "        0.87503505,  0.50552024,  0.5612116 ,  0.21300133,  0.46762088,\n",
       "        0.12458987,  0.13059299,  0.11742664,  0.59854978,  0.90387981,\n",
       "        0.63611528,  0.26924251,  0.16383979,  0.12149156,  0.2001776 ,\n",
       "        0.12304029,  0.12886813,  0.14644862,  0.35504988,  0.88285515,\n",
       "        0.15525557,  0.86479699,  0.50610103,  0.15384048,  0.15350674,\n",
       "        0.86095478,  0.37076657,  0.1242247 ,  0.6514729 ,  0.15297506,\n",
       "        0.24374948,  0.14689178,  0.11188783,  0.1877126 ,  0.45574163,\n",
       "        0.16891891,  0.11919252,  0.1476362 ,  0.91808224,  0.41721849,\n",
       "        0.53071499,  0.15426318,  0.69704934,  0.14692785,  0.81741993,\n",
       "        0.91276813,  0.15445592,  0.18802684,  0.14738105,  0.67188733,\n",
       "        0.18448538,  0.8846729 ,  0.11742971,  0.13421423,  0.55693783,\n",
       "        0.16671143,  0.88613254,  0.85179649,  0.11810927,  0.92713048,\n",
       "        0.25688178,  0.12330899,  0.28750724,  0.91050784,  0.17099599,\n",
       "        0.15045861,  0.9052104 ,  0.17749892,  0.12548342,  0.88788583,\n",
       "        0.89653278,  0.47588181,  0.1632835 ,  0.23752109,  0.23594666,\n",
       "        0.13492996,  0.13567074,  0.50200084,  0.53634002,  0.15321821,\n",
       "        0.83181342,  0.12590977,  0.09830351,  0.14306865,  0.48433558,\n",
       "        0.34568052,  0.89154912,  0.41722998,  0.12181593,  0.12009865,\n",
       "        0.91452435,  0.13991194,  0.91834099,  0.12732449,  0.13621139,\n",
       "        0.89098271,  0.1259753 ,  0.91532638,  0.33845956,  0.36306226,\n",
       "        0.46486264,  0.15710574,  0.2873392 ,  0.66059926,  0.64897117,\n",
       "        0.64783005,  0.92179878,  0.51216431,  0.11706107,  0.83271699,\n",
       "        0.1104782 ,  0.11743143,  0.43041973])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fina_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.05263158  1.        ] \n",
      "[ 0.          0.88157895  1.        ] \n",
      "[ 2.  1.  0.]\n",
      "[ 0.          0.05263158  1.        ] \n",
      "[ 0.          0.88157895  1.        ] \n",
      "[ 2.  1.  0.]\n",
      "auc_proba:  0.914473684211\n",
      "auc_sysout_label:  0.914473684211\n"
     ]
    }
   ],
   "source": [
    "fp,tp,thr=roc_curve(test_label,fina_proba)#参数为测试集样本的参考标签，以及系统输出的概率\n",
    "fp1,tp1,thr1=roc_curve(test_label,fina_sysout)\n",
    "print fp,\"\\n\",tp,\"\\n\",thr\n",
    "print fp1,\"\\n\",tp1,\"\\n\",thr1\n",
    "print \"auc_proba: \",auc(fp,tp)\n",
    "print \"auc_sysout_label: \",auc(fp1,tp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function get_dummies in module pandas.core.reshape:\n",
      "\n",
      "get_dummies(data, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False)\n",
      "    Convert categorical variable into dummy/indicator variables\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    data : array-like, Series, or DataFrame\n",
      "    prefix : string, list of strings, or dict of strings, default None\n",
      "        String to append DataFrame column names\n",
      "        Pass a list with length equal to the number of columns\n",
      "        when calling get_dummies on a DataFrame. Alternativly, `prefix`\n",
      "        can be a dictionary mapping column names to prefixes.\n",
      "    prefix_sep : string, default '_'\n",
      "        If appending prefix, separator/delimiter to use. Or pass a\n",
      "        list or dictionary as with `prefix.`\n",
      "    dummy_na : bool, default False\n",
      "        Add a column to indicate NaNs, if False NaNs are ignored.\n",
      "    columns : list-like, default None\n",
      "        Column names in the DataFrame to be encoded.\n",
      "        If `columns` is None then all the columns with\n",
      "        `object` or `category` dtype will be converted.\n",
      "    sparse : bool, default False\n",
      "        Whether the dummy columns should be sparse or not.  Returns\n",
      "        SparseDataFrame if `data` is a Series or if all columns are included.\n",
      "        Otherwise returns a DataFrame with some SparseBlocks.\n",
      "    \n",
      "        .. versionadded:: 0.16.1\n",
      "    drop_first : bool, default False\n",
      "        Whether to get k-1 dummies out of n categorical levels by removing the\n",
      "        first level.\n",
      "    \n",
      "        .. versionadded:: 0.18.0\n",
      "    Returns\n",
      "    -------\n",
      "    dummies : DataFrame or SparseDataFrame\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import pandas as pd\n",
      "    >>> s = pd.Series(list('abca'))\n",
      "    \n",
      "    >>> pd.get_dummies(s)\n",
      "       a  b  c\n",
      "    0  1  0  0\n",
      "    1  0  1  0\n",
      "    2  0  0  1\n",
      "    3  1  0  0\n",
      "    \n",
      "    >>> s1 = ['a', 'b', np.nan]\n",
      "    \n",
      "    >>> pd.get_dummies(s1)\n",
      "       a  b\n",
      "    0  1  0\n",
      "    1  0  1\n",
      "    2  0  0\n",
      "    \n",
      "    >>> pd.get_dummies(s1, dummy_na=True)\n",
      "       a  b  NaN\n",
      "    0  1  0    0\n",
      "    1  0  1    0\n",
      "    2  0  0    1\n",
      "    \n",
      "    >>> df = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['b', 'a', 'c'],\n",
      "                        'C': [1, 2, 3]})\n",
      "    \n",
      "    >>> pd.get_dummies(df, prefix=['col1', 'col2'])\n",
      "       C  col1_a  col1_b  col2_a  col2_b  col2_c\n",
      "    0  1       1       0       0       1       0\n",
      "    1  2       0       1       1       0       0\n",
      "    2  3       1       0       0       0       1\n",
      "    \n",
      "    >>> pd.get_dummies(pd.Series(list('abcaa')))\n",
      "       a  b  c\n",
      "    0  1  0  0\n",
      "    1  0  1  0\n",
      "    2  0  0  1\n",
      "    3  1  0  0\n",
      "    4  1  0  0\n",
      "    \n",
      "    >>> pd.get_dummies(pd.Series(list('abcaa')), drop_first=True))\n",
      "       b  c\n",
      "    0  0  0\n",
      "    1  1  0\n",
      "    2  0  1\n",
      "    3  0  0\n",
      "    4  0  0\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    Series.str.get_dummies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.get_dummies)#categorical variable：分类变量；dummies variables:虚拟变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fina_sysout.tofile(\"test_sysout.csv\",sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_label.tofile(\"test_ref.csv\",sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[252  14]\n",
      " [ 18 134]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.95      0.94       266\n",
      "        1.0       0.91      0.88      0.89       152\n",
      "\n",
      "avg / total       0.92      0.92      0.92       418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve,auc,confusion_matrix,classification_report\n",
    "from scipy import interp\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes=2\n",
    "lw=4\n",
    "path=r\"/media/zzpp220/Data/Linux_Documents/DOWNLOAD/python-DataAnalysis/Titanic/\"\n",
    "fina_sysout=np.loadtxt(path+\"test_sysout.csv\")\n",
    "test_label=np.loadtxt(path+\"test_ref.csv\")\n",
    "\n",
    "#==============================================================================\n",
    "# fina_sysout=np.concatenate(fina_sysout)\n",
    "# fina_sysout=np.array([int(i) for i in fina_sysout])\n",
    "# test_label=np.concatenate(test_label)\n",
    "#==============================================================================\n",
    "\n",
    "print confusion_matrix(test_label,fina_sysout)\n",
    "print classification_report(test_label,fina_sysout)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    y_ref=np.array(pd.get_dummies(fina_sysout))[:, i]\n",
    "    y_sys=np.array(pd.get_dummies(test_label))[:, i]\n",
    "    fpr[i], tpr[i], _ = roc_curve(np.array(pd.get_dummies(fina_sysout))[:, i], np.array(pd.get_dummies(test_label))[:, i])#一类一类的比较结果，得到n_Calss条roc,_代表这个变量用不到，返回3个数组.每个数组都是递增的\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "c=np.concatenate([fpr[i] for i in range(n_classes)])\n",
    "np.unique(c)\n",
    "\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))##3个元素\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])##内插值？\n",
    "\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr#fpr的均值？\n",
    "tpr[\"macro\"] = mean_tpr#tpr的均值？\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])#auc的均值？\n",
    "\n",
    "plt.figure(figsize=(10,7))#横坐标、纵坐标\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='\"macro\"-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='purple', linestyle=':', linewidth=6)\n",
    "\n",
    "colors = ['aqua', 'darkorange', 'cornflowerblue']#3类\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))#对每一类都有一个roc曲线\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--',color='red', lw=3)#lw=linewidth\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.annotate('Random Guess',(.5,.48),color='red')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic for Naive Bayes - IRIS DATASET')\n",
    "plt.legend(loc=\"lower right\")#图例，右下角\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
